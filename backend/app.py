from flask import Flask, request, jsonify, send_file
from flask_cors import CORS
from pathlib import Path
import os
import tempfile
import shutil
from datetime import datetime
import traceback
import numpy as np
import sys
import json
import cv2

# ğŸ”§ é—œéµä¿®æ­£ï¼šç¢ºä¿å°ˆæ¡ˆæ ¹ç›®éŒ„åœ¨ Python è·¯å¾‘ä¸­
WEBSITE_ROOT = Path(__file__).parent.parent  # 0809-3 å°ˆæ¡ˆæ ¹ç›®éŒ„
BACKEND_ROOT = Path(__file__).parent         # backend ç›®éŒ„

# ğŸ”§ å°‡å°ˆæ¡ˆç›®éŒ„åŠ å…¥ Python è·¯å¾‘
sys.path.insert(0, str(WEBSITE_ROOT))  # åŠ å…¥å°ˆæ¡ˆæ ¹ç›®éŒ„
sys.path.insert(0, str(BACKEND_ROOT))  # åŠ å…¥ backend ç›®éŒ„

print(f"ğŸ  å°ˆæ¡ˆæ ¹ç›®éŒ„: {WEBSITE_ROOT}")
print(f"ğŸ“ å¾Œç«¯ç›®éŒ„: {BACKEND_ROOT}")
print(f"ğŸ”§ Python è·¯å¾‘å·²æ›´æ–°")

# ç¾åœ¨å°å…¥æ¨¡çµ„ï¼ˆç¢ºä¿é€™äº›æª”æ¡ˆå­˜åœ¨æ–¼ backend/modules/ ä¸­ï¼‰
try:
    from modules.adjust_image import align_images_api, validate_alignment_parameters
    from modules.sam2_segmenter import (
        segment_image_api, segment_multiple_images_api
    )
    from modules.mask_matching import (
        match_masks_with_images_api, load_masks_from_pickle, load_masks_from_individual_files,
        validate_mask_matching_parameters
    )
    from modules.detect_change import detect_changes_with_texture_analysis
    from modules.video_processor import VideoProcessor, extract_video_frames_api

    from utils import (
        save_uploaded_file, create_temp_directory, cleanup_temp_files,
        validate_file_type, get_file_info, create_error_response,
        create_success_response
    )
    print("âœ… æ‰€æœ‰æ¨¡çµ„å°å…¥æˆåŠŸ")
except ImportError as e:
    print(f"âŒ æ¨¡çµ„å°å…¥å¤±æ•—: {e}")
    print("è«‹ç¢ºèªä»¥ä¸‹æª”æ¡ˆæ˜¯å¦å­˜åœ¨ï¼š")
    print("  - backend/modules/adjust_image.py")
    print("  - backend/modules/sam2_segmenter.py")
    print("  - backend/modules/mask_matching.py")
    print("  - backend/modules/detect_change.py")
    print("  - backend/utils.py")

app = Flask(__name__)
CORS(app)

# é…ç½® - çµ±ä¸€è·¯å¾‘ç®¡ç†
app.config['MAX_CONTENT_LENGTH'] = 100 * 1024 * 1024  # 100MB
app.config['UPLOAD_FOLDER'] = str(WEBSITE_ROOT / 'results' / 'uploads')
app.config['TEMP_FOLDER'] = str(WEBSITE_ROOT / 'results' / 'temp')
app.config['RESULTS_FOLDER'] = str(WEBSITE_ROOT / 'results')
app.config['CHECKPOINT_FOLDER'] = str(WEBSITE_ROOT / 'checkpoint')  # ä¿®æ­£ï¼šcheckpoint ä¸æ˜¯ checkpoints
app.config['CONFIG_FOLDER'] = str(WEBSITE_ROOT / 'configs')

print(f"ğŸ“ çµæœç›®éŒ„: {app.config['RESULTS_FOLDER']}")
print(f"ğŸ“¤ ä¸Šå‚³ç›®éŒ„: {app.config['UPLOAD_FOLDER']}")
print(f"ğŸ¤– æ¨¡å‹ç›®éŒ„: {app.config['CHECKPOINT_FOLDER']}")
print(f"âš™ï¸ é…ç½®ç›®éŒ„: {app.config['CONFIG_FOLDER']}")

# å‰µå»ºå¿…è¦çš„è³‡æ–™å¤¾
for folder_path in [app.config['UPLOAD_FOLDER'], app.config['TEMP_FOLDER'], app.config['RESULTS_FOLDER']]:
    Path(folder_path).mkdir(exist_ok=True, parents=True)
    print(f"âœ… ç¢ºä¿ç›®éŒ„å­˜åœ¨: {folder_path}")

def create_success_response(data, message="æ“ä½œæˆåŠŸ"):
    """å‰µå»ºæˆåŠŸå›æ‡‰"""
    return jsonify({
        'status': 'success',
        'message': message,
        'data': data,
        'timestamp': datetime.now().isoformat()
    })

def create_error_response(message, status_code=400, error_details=None):
    """å‰µå»ºéŒ¯èª¤å›æ‡‰"""
    response_data = {
        'status': 'error',
        'message': message,
        'timestamp': datetime.now().isoformat()
    }

    if error_details:
        response_data['error_details'] = error_details

    return jsonify(response_data), status_code

def generate_objects_data(detection_result, detection_dir):
    """ç”Ÿæˆç‰©ä»¶æª¢è¦–æ‰€éœ€çš„è³‡æ–™ - é‡æ–°è¨­è¨ˆç‚ºå±€éƒ¨å€åŸŸæª¢è¦–"""
    print("ğŸ” ç”Ÿæˆç‰©ä»¶æª¢è¦–è³‡æ–™...")

    disappeared_objects = []
    appeared_objects = []

    try:
        detection_path = Path(detection_dir)

        # æª¢æŸ¥æ¶ˆå¤±ç‰©ä»¶è³‡æ–™å¤¾
        disappear_folder = detection_path / 'Disappear'
        if disappear_folder.exists():
            print(f"ğŸ“ æª¢æŸ¥æ¶ˆå¤±ç‰©ä»¶è³‡æ–™å¤¾: {disappear_folder}")

            # ç²å–åŸå§‹åœ–ç‰‡è·¯å¾‘
            image1_original = detection_path / 'image1_original.jpg'
            image2_original = detection_path / 'image2_original.jpg'

            if image1_original.exists() and image2_original.exists():
                # ç²å–æ‰€æœ‰æ¶ˆå¤±é®ç½©ä¸¦æŒ‰åç¨±æ’åº
                mask_files = sorted(list(disappear_folder.glob('disappeared_mask_*.png')))

                # ç‚ºæ¯å€‹æ¶ˆå¤±é®ç½©ç”Ÿæˆå±€éƒ¨æª¢è¦–ï¼Œä½¿ç”¨é †åºç·¨è™Ÿ
                for idx, mask_file in enumerate(mask_files, 1):
                    # ğŸ”§ ä¿®æ”¹ï¼šä½¿ç”¨é †åºç·¨è™Ÿè€Œä¸æ˜¯åŸå§‹æª”æ¡ˆç·¨è™Ÿ
                    sequential_number = f'{idx:03d}'  # 001, 002, 003...

                    # ç”Ÿæˆè©²é®ç½©çš„å±€éƒ¨åœ–åƒï¼Œä½¿ç”¨é †åºç·¨è™Ÿ
                    crop_result = generate_mask_crop_images(
                        str(image1_original),
                        str(image2_original),
                        str(mask_file),
                        detection_dir,
                        sequential_number,  # ä½¿ç”¨é †åºç·¨è™Ÿ
                        'disappeared'
                    )

                    if crop_result:
                        # ğŸ”§ è¨ˆç®—å¯¦éš›çš„é®ç½©çµ±è¨ˆæ•¸æ“š
                        mask_stats = calculate_mask_statistics(str(mask_file), str(image1_original), str(image2_original))

                        disappeared_objects.append({
                            'name': f'æ¶ˆå¤±ç‰©ä»¶ {sequential_number}',  # ä½¿ç”¨é †åºç·¨è™Ÿé¡¯ç¤º
                            'before_path': crop_result['before_crop'],
                            'after_path': crop_result['after_crop'],
                            'mask_path': crop_result['mask_overlay'],
                            'original_mask': f'Disappear/{mask_file.name}',
                            'confidence': mask_stats['confidence'],
                            'changeRatio': mask_stats['change_ratio'],
                            'changedPixels': mask_stats['changed_pixels'],
                            'maskArea': mask_stats['mask_area'],
                            'bbox': crop_result['bbox']
                        })

        # æª¢æŸ¥æ–°å¢ç‰©ä»¶è³‡æ–™å¤¾
        newadded_folder = detection_path / 'NewAdded'
        if newadded_folder.exists():
            print(f"ğŸ“ æª¢æŸ¥æ–°å¢ç‰©ä»¶è³‡æ–™å¤¾: {newadded_folder}")

            # ç²å–åŸå§‹åœ–ç‰‡è·¯å¾‘
            image1_original = detection_path / 'image1_original.jpg'
            image2_original = detection_path / 'image2_original.jpg'

            if image1_original.exists() and image2_original.exists():
                # ç²å–æ‰€æœ‰æ–°å¢é®ç½©ä¸¦æŒ‰åç¨±æ’åº
                mask_files = sorted(list(newadded_folder.glob('new_mask_*.png')))

                # ç‚ºæ¯å€‹æ–°å¢é®ç½©ç”Ÿæˆå±€éƒ¨æª¢è¦–ï¼Œä½¿ç”¨ä¸åŒçš„ç·¨è™Ÿç¯„åœï¼ˆå¾æ¶ˆå¤±ç‰©ä»¶æ•¸é‡+1é–‹å§‹ï¼‰
                disappeared_count = len(disappeared_objects)  # ç²å–å·²è™•ç†çš„æ¶ˆå¤±ç‰©ä»¶æ•¸é‡
                for idx, mask_file in enumerate(mask_files, disappeared_count + 1):
                    # ğŸ”§ ä¿®æ”¹ï¼šä½¿ç”¨æ¥çºŒç·¨è™Ÿï¼Œé¿å…èˆ‡æ¶ˆå¤±ç‰©ä»¶è¡çª
                    sequential_number = f'{idx:03d}'  # å¾æ¶ˆå¤±ç‰©ä»¶æ•¸é‡+1é–‹å§‹ç·¨è™Ÿ

                    # ç”Ÿæˆè©²é®ç½©çš„å±€éƒ¨åœ–åƒï¼Œä½¿ç”¨é †åºç·¨è™Ÿ
                    crop_result = generate_mask_crop_images(
                        str(image1_original),
                        str(image2_original),
                        str(mask_file),
                        detection_dir,
                        sequential_number,  # ä½¿ç”¨ä¸è¡çªçš„é †åºç·¨è™Ÿ
                        'appeared'
                    )

                    if crop_result:
                        # ğŸ”§ è¨ˆç®—å¯¦éš›çš„é®ç½©çµ±è¨ˆæ•¸æ“š
                        mask_stats = calculate_mask_statistics(str(mask_file), str(image1_original), str(image2_original))

                        appeared_objects.append({
                            'name': f'æ–°å¢ç‰©ä»¶ {sequential_number}',  # ä½¿ç”¨é †åºç·¨è™Ÿé¡¯ç¤º
                            'before_path': crop_result['before_crop'],
                            'after_path': crop_result['after_crop'],
                            'mask_path': crop_result['mask_overlay'],
                            'original_mask': f'NewAdded/{mask_file.name}',
                            'confidence': mask_stats['confidence'],
                            'changeRatio': mask_stats['change_ratio'],
                            'changedPixels': mask_stats['changed_pixels'],
                            'maskArea': mask_stats['mask_area'],
                            'bbox': crop_result['bbox']
                        })

        print(f"âœ… ç‰©ä»¶æª¢è¦–è³‡æ–™ç”Ÿæˆå®Œæˆ:")
        print(f"   ğŸ“‰ æ¶ˆå¤±ç‰©ä»¶: {len(disappeared_objects)} å€‹")
        print(f"   ğŸ“ˆ æ–°å¢ç‰©ä»¶: {len(appeared_objects)} å€‹")

        return {
            'disappeared': disappeared_objects,
            'appeared': appeared_objects
        }

    except Exception as e:
        print(f"âŒ ç”Ÿæˆç‰©ä»¶æª¢è¦–è³‡æ–™æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        import traceback
        traceback.print_exc()
        return {'disappeared': [], 'appeared': []}

def generate_mask_crop_images(image1_path, image2_path, mask_path, output_dir, object_id, object_type):
    """ç‚ºå–®å€‹é®ç½©ç”Ÿæˆè£åˆ‡çš„å±€éƒ¨åœ–åƒ"""
    try:
        import cv2
        import numpy as np

        print(f"ğŸ¯ è™•ç† {object_type} ç‰©ä»¶: {object_id}")

        # è¼‰å…¥åœ–ç‰‡å’Œé®ç½©
        image1 = cv2.imread(image1_path)
        image2 = cv2.imread(image2_path)
        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)

        if image1 is None or image2 is None or mask is None:
            print(f"âŒ ç„¡æ³•è¼‰å…¥æª”æ¡ˆ: {image1_path}, {image2_path}, {mask_path}")
            return None

        # æ‰¾åˆ°é®ç½©çš„é‚Šç•Œæ¡†
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
        if not contours:
            print(f"âŒ åœ¨é®ç½©ä¸­æ‰¾ä¸åˆ°è¼ªå»“: {mask_path}")
            return None

        # è¨ˆç®—æ‰€æœ‰è¼ªå»“çš„ç¸½é‚Šç•Œæ¡†
        x_min, y_min, x_max, y_max = float('inf'), float('inf'), 0, 0
        for contour in contours:
            x, y, w, h = cv2.boundingRect(contour)
            x_min = min(x_min, x)
            y_min = min(y_min, y)
            x_max = max(x_max, x + w)
            y_max = max(y_max, y + h)

        # ğŸ”§ å‹•æ…‹èª¿æ•´è£åˆ‡å€åŸŸï¼šæ ¹æ“šé®ç½©å¤§å°è‡ªé©æ‡‰ï¼ŒåŠ ä¸Šé©ç•¶çš„é‚Šè·
        original_mask_w, original_mask_h = x_max - x_min, y_max - y_min

        # æ ¹æ“šé®ç½©å°ºå¯¸å‹•æ…‹èª¿æ•´é‚Šè·
        # å°ç‰©ä»¶ç”¨è¼ƒå¤§æ¯”ä¾‹çš„é‚Šè·ï¼Œå¤§ç‰©ä»¶ç”¨è¼ƒå°æ¯”ä¾‹çš„é‚Šè·
        margin_ratio = max(0.3, min(0.8, 100 / max(original_mask_w, original_mask_h)))
        dynamic_margin = int(max(original_mask_w, original_mask_h) * margin_ratio)

        # æ‡‰ç”¨å‹•æ…‹é‚Šè·åˆ°é‚Šç•Œæ¡†
        h_img, w_img = image1.shape[:2]
        x_min = max(0, x_min - dynamic_margin)
        y_min = max(0, y_min - dynamic_margin)
        x_max = min(w_img, x_max + dynamic_margin)
        y_max = min(h_img, y_max + dynamic_margin)

        crop_w, crop_h = x_max - x_min, y_max - y_min

        print(f"ğŸ¯ å‹•æ…‹è£åˆ‡: é®ç½©å°ºå¯¸({original_mask_w}x{original_mask_h}) -> é‚Šè·({dynamic_margin}px) -> æœ€çµ‚è£åˆ‡({crop_w}x{crop_h})")

        # è£åˆ‡åœ–åƒ
        crop1 = image1[y_min:y_max, x_min:x_max]
        crop2 = image2[y_min:y_max, x_min:x_max]
        crop_mask = mask[y_min:y_max, x_min:x_max]

        # å‰µå»ºè¼¸å‡ºç›®éŒ„
        crops_dir = Path(output_dir) / 'crops'
        crops_dir.mkdir(exist_ok=True)

        # ä¿å­˜è£åˆ‡åœ–åƒ
        before_crop_path = crops_dir / f'{object_id}_before.jpg'
        after_crop_path = crops_dir / f'{object_id}_after.jpg'

        cv2.imwrite(str(before_crop_path), crop1)
        cv2.imwrite(str(after_crop_path), crop2)

        # å‰µå»ºç´”é®ç½©åœ–åƒï¼ˆç”¨æ–¼ç–ŠåŠ ï¼‰
        mask_overlay_path = crops_dir / f'{object_id}_mask.png'

        # å‰µå»ºRGBé®ç½©åœ–åƒ
        mask_rgb = np.zeros((crop_mask.shape[0], crop_mask.shape[1], 3), dtype=np.uint8)

        if object_type == 'disappeared':
            # æ¶ˆå¤±ç‰©ä»¶ï¼šç´…è‰²é®ç½©
            mask_rgb[crop_mask > 0] = [0, 0, 255]  # BGRæ ¼å¼çš„ç´…è‰²
        else:
            # æ–°å¢ç‰©ä»¶ï¼šç¶ è‰²é®ç½©
            mask_rgb[crop_mask > 0] = [0, 255, 0]  # BGRæ ¼å¼çš„ç¶ è‰²

        # ä¿å­˜é®ç½©åœ–åƒï¼ˆPNGæ ¼å¼æ”¯æ´é€æ˜åº¦ï¼‰
        # å‰µå»ºå¸¶é€æ˜åº¦çš„é®ç½©
        mask_rgba = np.zeros((crop_mask.shape[0], crop_mask.shape[1], 4), dtype=np.uint8)
        if object_type == 'disappeared':
            mask_rgba[crop_mask > 0] = [0, 0, 255, 160]  # ç´…è‰²ï¼Œé€æ˜åº¦160
        else:
            mask_rgba[crop_mask > 0] = [0, 255, 0, 160]  # ç¶ è‰²ï¼Œé€æ˜åº¦160

        cv2.imwrite(str(mask_overlay_path), mask_rgba)

        print(f"âœ… æˆåŠŸç”Ÿæˆå±€éƒ¨æª¢è¦–: {object_id}")
        print(f"  è£åˆ‡å€åŸŸ: ({x_min}, {y_min}) - ({x_max}, {y_max})")
        print(f"  å°ºå¯¸: {crop_w} x {crop_h}")

        return {
            'before_crop': f'crops/{object_id}_before.jpg',
            'after_crop': f'crops/{object_id}_after.jpg',
            'mask_overlay': f'crops/{object_id}_mask.png',
            'bbox': {
                'x': int(x_min),
                'y': int(y_min),
                'width': int(x_max - x_min),
                'height': int(y_max - y_min)
            }
        }

    except Exception as e:
        print(f"âŒ ç”Ÿæˆå±€éƒ¨æª¢è¦–å¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return None

def calculate_mask_statistics(mask_path, image1_path, image2_path):
    """è¨ˆç®—é®ç½©çš„å¯¦éš›çµ±è¨ˆæ•¸æ“š"""
    try:
        import cv2
        import numpy as np
        from pathlib import Path

        # è¼‰å…¥é®ç½©å’Œåœ–ç‰‡
        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)
        image1 = cv2.imread(image1_path)
        image2 = cv2.imread(image2_path)

        if mask is None:
            print(f"âŒ ç„¡æ³•è¼‰å…¥é®ç½©: {mask_path}")
            return get_default_mask_stats()

        # è¨ˆç®—é®ç½©é¢ç©
        mask_area = np.sum(mask > 0)

        # ğŸ”§ æ”¹é€²è®ŠåŒ–ç¨‹åº¦è¨ˆç®—ï¼šåŸºæ–¼é®ç½©å€åŸŸå…§çš„å¯¦éš›åƒç´ å·®ç•°
        if image1 is not None and image2 is not None:
            # ç¢ºä¿æ‰€æœ‰åœ–ç‰‡å°ºå¯¸ä¸€è‡´
            if image1.shape != image2.shape or image1.shape[:2] != mask.shape:
                # èª¿æ•´åœ–ç‰‡å¤§å°ä»¥åŒ¹é…é®ç½©
                h, w = mask.shape
                image1 = cv2.resize(image1, (w, h))
                image2 = cv2.resize(image2, (w, h))

            # å°‡åœ–ç‰‡è½‰æ›ç‚ºç°éšä»¥ä¾¿æ¯”è¼ƒ
            gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)
            gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)

            # è¨ˆç®—å…©å¼µåœ–ç‰‡åœ¨é®ç½©å€åŸŸå…§çš„å·®ç•°
            diff = cv2.absdiff(gray1, gray2)

            # åªè€ƒæ…®é®ç½©å€åŸŸå…§çš„å·®ç•°
            masked_diff = diff * (mask > 0).astype(np.uint8)

            # è¨ˆç®—é®ç½©å€åŸŸå…§çš„å¹³å‡å·®ç•°å¼·åº¦
            mask_pixels = mask > 0
            if np.sum(mask_pixels) > 0:
                avg_diff = np.mean(masked_diff[mask_pixels])
                max_diff = np.max(masked_diff[mask_pixels])

                # åŸºæ–¼å¹³å‡å·®ç•°å’Œæœ€å¤§å·®ç•°è¨ˆç®—è®ŠåŒ–ç¨‹åº¦
                # avg_diff ç¯„åœé€šå¸¸æ˜¯ 0-255ï¼Œæˆ‘å€‘å°‡å…¶è½‰æ›ç‚º 0-100%
                intensity_score = (avg_diff / 255.0) * 100
                peak_score = (max_diff / 255.0) * 100

                # ç¶œåˆè©•åˆ†ï¼š70% å¹³å‡å·®ç•° + 30% å³°å€¼å·®ç•°
                change_ratio = (intensity_score * 0.7 + peak_score * 0.3)

                # æ ¹æ“šè®ŠåŒ–å¼·åº¦èª¿æ•´ç¯„åœ
                if change_ratio > 40:
                    # å¼·çƒˆè®ŠåŒ–
                    change_ratio = 65 + (change_ratio - 40) * 0.5
                elif change_ratio > 20:
                    # ä¸­ç­‰è®ŠåŒ–
                    change_ratio = 25 + (change_ratio - 20) * 2.0
                elif change_ratio > 5:
                    # è¼•å¾®è®ŠåŒ–
                    change_ratio = 8 + (change_ratio - 5) * 1.13
                else:
                    # æ¥µè¼•å¾®è®ŠåŒ–
                    change_ratio = max(1, change_ratio * 1.6)

                print(f"ğŸ” åƒç´ å·®ç•°åˆ†æ:")
                print(f"   å¹³å‡å·®ç•°å¼·åº¦: {avg_diff:.1f}/255 ({intensity_score:.1f}%)")
                print(f"   æœ€å¤§å·®ç•°å¼·åº¦: {max_diff:.1f}/255 ({peak_score:.1f}%)")
                print(f"   é®ç½©å€åŸŸåƒç´ : {np.sum(mask_pixels)}")
            else:
                change_ratio = 1  # æ²’æœ‰é®ç½©å€åŸŸçš„æƒ…æ³

        else:
            # å‚™ç”¨è¨ˆç®—æ–¹æ³•ï¼šåŸºæ–¼é®ç½©å¯†åº¦
            total_pixels = mask.shape[0] * mask.shape[1]
            change_density = (mask_area / total_pixels) * 100
            change_ratio = min(50, max(5, change_density * 1.5))

        # ğŸ”§ æ”¹é€²ä¿¡å¿ƒåº¦è¨ˆç®—ï¼šåŸºæ–¼é®ç½©çš„è¤‡é›œåº¦å’Œå¤§å°
        contours, _ = cv2.findContours(mask, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)

        if len(contours) > 0:
            # åŸºæ–¼æœ€å¤§è¼ªå»“çš„é¢ç©å’Œå½¢ç‹€è¨ˆç®—ä¿¡å¿ƒåº¦
            largest_contour = max(contours, key=cv2.contourArea)
            contour_area = cv2.contourArea(largest_contour)

            # è¨ˆç®—è¼ªå»“çš„å‘¨é•·å’Œé¢ç©æ¯”ï¼ˆè¡¡é‡å½¢ç‹€çš„è¤‡é›œåº¦ï¼‰
            perimeter = cv2.arcLength(largest_contour, True)
            if perimeter > 0:
                compactness = 4 * np.pi * contour_area / (perimeter * perimeter)
            else:
                compactness = 0

            # åŸºæ–¼é¢ç©å¤§å°å’Œå½¢ç‹€è¤‡é›œåº¦è¨ˆç®—ä¿¡å¿ƒåº¦
            area_score = min(60, (contour_area / 1000) * 20)  # é¢ç©è¶Šå¤§ä¿¡å¿ƒåº¦è¶Šé«˜
            shape_score = compactness * 25  # å½¢ç‹€è¶Šè¦å‰‡ä¿¡å¿ƒåº¦è¶Šé«˜
            base_confidence = 50 + area_score + shape_score

            confidence = max(45, min(98, base_confidence))
        else:
            confidence = 45  # æ²’æœ‰æ˜é¡¯è¼ªå»“çš„æƒ…æ³

        # ğŸ”§ å‹•æ…‹è®ŠåŒ–ç¨‹åº¦ç¯„åœæ§åˆ¶
        change_ratio = max(1, min(95, change_ratio))  # ç¢ºä¿åœ¨ 1-95% ç¯„åœå…§

        print(f"ğŸ“Š é®ç½©çµ±è¨ˆ {Path(mask_path).name}:")
        print(f"   é¢ç©: {mask_area} åƒç´ ")
        print(f"   è®ŠåŒ–ç¨‹åº¦: {round(change_ratio, 1)}%")
        print(f"   ä¿¡å¿ƒåº¦: {round(confidence)}%")

        return {
            'confidence': round(confidence),
            'change_ratio': round(change_ratio, 1),
            'changed_pixels': int(mask_area),
            'mask_area': int(mask_area)
        }

    except Exception as e:
        print(f"âŒ è¨ˆç®—é®ç½©çµ±è¨ˆæ•¸æ“šå¤±æ•—: {e}")
        import traceback
        traceback.print_exc()
        return get_default_mask_stats()

def get_default_mask_stats():
    """è¿”å›é è¨­çš„é®ç½©çµ±è¨ˆæ•¸æ“š"""
    return {
        'confidence': 65,
        'change_ratio': 25,
        'changed_pixels': 800,
        'mask_area': 800
    }

# ğŸ”§ ç›´æ¥å®šç¾©ï¼šé®ç½©è¼‰å…¥å‡½æ•¸
def load_masks_from_pickle(masks_1_path, masks_2_path):
    """
    ğŸ”§ ä¿®æ”¹ç‰ˆï¼šåŒæ™‚æ”¯æ´ pickle æª”æ¡ˆå’Œå€‹åˆ¥é®ç½©æª”æ¡ˆè¼‰å…¥
    """
    import pickle
    import numpy as np
    import cv2
    from pathlib import Path

    try:
        print(f"ğŸ”„ è¼‰å…¥é®ç½©è³‡æ–™...")
        print(f"  - æª”æ¡ˆ1: {Path(masks_1_path).name}")
        print(f"  - æª”æ¡ˆ2: {Path(masks_2_path).name}")

        # ğŸ†• æª¢æŸ¥æ˜¯å¦ç‚º pickle æª”æ¡ˆæˆ–ç›®éŒ„
        path1 = Path(masks_1_path)
        path2 = Path(masks_2_path)

        masks_data_1 = None
        masks_data_2 = None

        # è™•ç†ç¬¬ä¸€å€‹è¼¸å…¥
        if path1.is_file() and path1.suffix == '.pkl':
            # å¾ pickle æª”æ¡ˆè¼‰å…¥
            with open(path1, 'rb') as f:
                pickle_data_1 = pickle.load(f)

            # ğŸ†• æª¢æŸ¥æ˜¯å¦ç‚ºæ–°çš„ 2 æ¬¡åˆ†å‰²æ ¼å¼
            if 'all_masks_results' in pickle_data_1:
                # æ–°æ ¼å¼ï¼šå¾ all_masks ç›®éŒ„è¼‰å…¥
                all_masks_dir = pickle_data_1['all_masks_results'].get('masks_directory')
                if all_masks_dir and Path(all_masks_dir).exists():
                    masks_data_1 = load_masks_from_directory(all_masks_dir)
                else:
                    print(f"âš ï¸ all_masks ç›®éŒ„ä¸å­˜åœ¨ï¼Œå˜—è©¦å¾ pickle è³‡æ–™è¼‰å…¥")
                    masks_data_1 = extract_masks_from_pickle(pickle_data_1)
            else:
                # èˆŠæ ¼å¼ï¼šç›´æ¥å¾ pickle è¼‰å…¥
                masks_data_1 = extract_masks_from_pickle(pickle_data_1)

        elif path1.is_dir():
            # ç›´æ¥å¾ç›®éŒ„è¼‰å…¥
            masks_data_1 = load_masks_from_directory(str(path1))
        else:
            print(f"âŒ ä¸æ”¯æ´çš„æª”æ¡ˆæ ¼å¼: {path1}")
            return None, None

        # è™•ç†ç¬¬äºŒå€‹è¼¸å…¥ï¼ˆåŒæ¨£é‚è¼¯ï¼‰
        if path2.is_file() and path2.suffix == '.pkl':
            with open(path2, 'rb') as f:
                pickle_data_2 = pickle.load(f)

            if 'all_masks_results' in pickle_data_2:
                all_masks_dir = pickle_data_2['all_masks_results'].get('masks_directory')
                if all_masks_dir and Path(all_masks_dir).exists():
                    masks_data_2 = load_masks_from_directory(all_masks_dir)
                else:
                    masks_data_2 = extract_masks_from_pickle(pickle_data_2)
            else:
                masks_data_2 = extract_masks_from_pickle(pickle_data_2)

        elif path2.is_dir():
            masks_data_2 = load_masks_from_directory(str(path2))
        else:
            print(f"âŒ ä¸æ”¯æ´çš„æª”æ¡ˆæ ¼å¼: {path2}")
            return None, None

        if masks_data_1 is None or masks_data_2 is None:
            print(f"âŒ è¼‰å…¥é®ç½©è³‡æ–™å¤±æ•—")
            return None, None

        print(f"âœ… é®ç½©è³‡æ–™è¼‰å…¥æˆåŠŸ:")
        print(f"  - æª”æ¡ˆ1 é®ç½©æ•¸é‡: {len(masks_data_1.get('masks', []))}")
        print(f"  - æª”æ¡ˆ2 é®ç½©æ•¸é‡: {len(masks_data_2.get('masks', []))}")

        return masks_data_1, masks_data_2

    except FileNotFoundError as e:
        print(f"âŒ éŒ¯èª¤ï¼šæ‰¾ä¸åˆ°é®ç½©æª”æ¡ˆ - {e}")
        return None, None
    except Exception as e:
        print(f"âŒ è¼‰å…¥é®ç½©æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None, None

# ğŸ”§ ä¹Ÿéœ€è¦é€™äº›è¼”åŠ©å‡½æ•¸
def load_masks_from_directory(masks_dir):
    """å¾æŒ‡å®šç›®éŒ„è¼‰å…¥æ‰€æœ‰é®ç½©æª”æ¡ˆä¸¦è¨ˆç®—å…ƒè³‡æ–™"""
    try:
        masks_path = Path(masks_dir)
        if not masks_path.exists():
            print(f"âŒ é®ç½©ç›®éŒ„ä¸å­˜åœ¨: {masks_dir}")
            return None

        # æ‰¾å‡ºæ‰€æœ‰é®ç½©æª”æ¡ˆ
        mask_files = sorted(list(masks_path.glob("mask_*.png")))

        if len(mask_files) == 0:
            print(f"âš ï¸ åœ¨ç›®éŒ„ {masks_dir} ä¸­æ‰¾ä¸åˆ°é®ç½©æª”æ¡ˆ")
            return None

        print(f"ğŸ“ åœ¨ {masks_path.name} ä¸­æ‰¾åˆ° {len(mask_files)} å€‹é®ç½©æª”æ¡ˆ")

        masks = []
        centroids = []
        areas = []
        bboxes = []

        for i, mask_file in enumerate(mask_files):
            try:
                # è¼‰å…¥é®ç½©åœ–åƒ
                mask_img = cv2.imread(str(mask_file), cv2.IMREAD_GRAYSCALE)
                if mask_img is None:
                    print(f"âš ï¸ ç„¡æ³•è¼‰å…¥é®ç½©æª”æ¡ˆ: {mask_file.name}")
                    continue

                # è½‰æ›ç‚ºäºŒå€¼åŒ–é®ç½©
                mask = (mask_img > 127).astype(np.float32)
                masks.append(mask)

                # è¨ˆç®—è³ªå¿ƒ
                y_coords, x_coords = np.where(mask > 0.5)
                if len(x_coords) > 0:
                    centroid_x = float(np.mean(x_coords))
                    centroid_y = float(np.mean(y_coords))
                    centroids.append((centroid_x, centroid_y))
                else:
                    centroids.append((0.0, 0.0))

                # è¨ˆç®—é¢ç©
                area = int(np.sum(mask > 0.5))
                areas.append(area)

                # è¨ˆç®—é‚Šç•Œæ¡†
                if len(x_coords) > 0:
                    bbox = [float(np.min(x_coords)), float(np.min(y_coords)),
                           float(np.max(x_coords)), float(np.max(y_coords))]
                else:
                    bbox = [0.0, 0.0, 0.0, 0.0]
                bboxes.append(bbox)

            except Exception as e:
                print(f"âš ï¸ è™•ç†é®ç½©æª”æ¡ˆ {mask_file.name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                continue

        if len(masks) == 0:
            print(f"âŒ æ²’æœ‰æˆåŠŸè¼‰å…¥ä»»ä½•é®ç½©")
            return None

        # çµ„ç¹”è³‡æ–™çµæ§‹
        masks_data = {
            'masks': masks,
            'centroids': centroids,
            'areas': areas,
            'bboxes': bboxes,
            'num_masks': len(masks),
            'mask_files': [str(f) for f in mask_files[:len(masks)]]
        }

        print(f"âœ… æˆåŠŸè™•ç† {len(masks)} å€‹é®ç½©æª”æ¡ˆ")
        return masks_data

    except Exception as e:
        print(f"âŒ è¼‰å…¥é®ç½©ç›®éŒ„æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

def extract_masks_from_pickle(pickle_data):
    """å¾ pickle è³‡æ–™ä¸­æå–é®ç½©è³‡è¨Šï¼ˆæ”¯æ´æ–°èˆŠæ ¼å¼ï¼‰"""
    try:
        # æ–°æ ¼å¼ï¼ˆ2æ¬¡åˆ†å‰²ï¼‰
        if 'all_masks_results' in pickle_data:
            # å„ªå…ˆä½¿ç”¨ all_masks ç›®éŒ„
            all_masks_dir = pickle_data['all_masks_results'].get('masks_directory')
            if all_masks_dir and Path(all_masks_dir).exists():
                return load_masks_from_directory(all_masks_dir)

            # å‚™ç”¨ï¼šå¾ pickle ä¸­çš„ masks é™£åˆ—è¼‰å…¥
            if 'masks' in pickle_data:
                return {
                    'masks': pickle_data['masks'],
                    'centroids': pickle_data.get('centroids', []),
                    'areas': pickle_data.get('areas', []),
                    'bboxes': pickle_data.get('bboxes', []),
                    'num_masks': len(pickle_data['masks'])
                }

        # èˆŠæ ¼å¼ï¼ˆç›´æ¥è¼‰å…¥ï¼‰
        if 'masks' in pickle_data:
            return {
                'masks': pickle_data['masks'],
                'centroids': pickle_data.get('centroids', []),
                'areas': pickle_data.get('areas', []),
                'bboxes': pickle_data.get('bboxes', []),
                'num_masks': len(pickle_data['masks'])
            }

        print(f"âš ï¸ pickle è³‡æ–™ä¸­æ‰¾ä¸åˆ°æœ‰æ•ˆçš„é®ç½©è³‡è¨Š")
        return None

    except Exception as e:
        print(f"âŒ å¾ pickle è³‡æ–™æå–é®ç½©æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
        return None

# ===== ğŸ”§ æ–°å¢ï¼šé‹è¡Œç®¡ç†ç³»çµ± =====

class RunManager:
    """é‹è¡Œæ¬¡æ•¸ç®¡ç†å™¨"""

    def __init__(self, results_root):
        self.results_root = Path(results_root)
        self.runs_dir = self.results_root / "runs"
        self.current_run_file = self.results_root / "current_run.txt"
        self.history_file = self.results_root / "run_history.json"

        # ç¢ºä¿å¿…è¦ç›®éŒ„å­˜åœ¨
        self.runs_dir.mkdir(parents=True, exist_ok=True)
        print(f"âœ… é‹è¡Œç®¡ç†å™¨åˆå§‹åŒ–å®Œæˆ: {self.runs_dir}")

    def get_next_run_number(self):
        """ç²å–ä¸‹ä¸€å€‹é‹è¡Œç·¨è™Ÿ"""
        try:
            if self.current_run_file.exists():
                with open(self.current_run_file, 'r') as f:
                    current_run = int(f.read().strip())
            else:
                current_run = 0

            next_run = current_run + 1

            # æ›´æ–°ç•¶å‰é‹è¡Œæ¬¡æ•¸
            with open(self.current_run_file, 'w') as f:
                f.write(str(next_run))

            return next_run

        except Exception as e:
            print(f"âš ï¸ ç²å–é‹è¡Œç·¨è™Ÿå¤±æ•—ï¼Œä½¿ç”¨é è¨­å€¼: {e}")
            return 1

    def create_run_directory(self, run_number=None):
        """å»ºç«‹æ–°çš„é‹è¡Œç›®éŒ„"""
        if run_number is None:
            run_number = self.get_next_run_number()

        run_dir = self.runs_dir / f"run_{run_number:03d}"

        # ğŸ”§ ä¿®æ”¹ï¼šå»ºç«‹6å€‹æ¨™æº–å­ç›®éŒ„
        subdirs = ['upload', 'alignment', 'sky_removal', 'segmentation', 'matching', 'detection']

        for subdir in subdirs:
            (run_dir / subdir).mkdir(parents=True, exist_ok=True)

        print(f"âœ… å»ºç«‹é‹è¡Œç›®éŒ„: {run_dir}")
        print(f"ğŸ“ åŒ…å«å­ç›®éŒ„: {', '.join(subdirs)}")

        # è¨˜éŒ„åˆ°æ­·å²
        self._record_run_history(run_number, run_dir)

        return str(run_dir), run_number

    def _record_run_history(self, run_number, run_dir):
        """è¨˜éŒ„é‹è¡Œæ­·å²"""
        try:
            history = []

            if self.history_file.exists():
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    history = json.load(f)

            run_record = {
                'run_number': run_number,
                'run_directory': str(run_dir),
                'start_time': datetime.now().isoformat(),
                'status': 'started',
                'steps_completed': [],
                'files_generated': {}
            }

            history.append(run_record)

            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(history, f, indent=2, ensure_ascii=False)

        except Exception as e:
            print(f"âš ï¸ è¨˜éŒ„é‹è¡Œæ­·å²å¤±æ•—: {e}")

    def update_run_status(self, run_number, step_name, status, files_info=None):
        """æ›´æ–°é‹è¡Œç‹€æ…‹"""
        try:
            if not self.history_file.exists():
                return

            with open(self.history_file, 'r', encoding='utf-8') as f:
                history = json.load(f)

            # æ‰¾åˆ°å°æ‡‰çš„é‹è¡Œè¨˜éŒ„
            for record in reversed(history):
                if record['run_number'] == run_number:
                    if step_name not in record['steps_completed']:
                        record['steps_completed'].append(step_name)

                    record['last_update'] = datetime.now().isoformat()
                    record['status'] = status

                    if files_info:
                        record['files_generated'][step_name] = files_info

                    break

            with open(self.history_file, 'w', encoding='utf-8') as f:
                json.dump(history, f, indent=2, ensure_ascii=False)

        except Exception as e:
            print(f"âš ï¸ æ›´æ–°é‹è¡Œç‹€æ…‹å¤±æ•—: {e}")

    def get_current_run_info(self):
        """ç²å–ç•¶å‰é‹è¡Œè³‡è¨Š"""
        try:
            if not self.current_run_file.exists():
                return None

            with open(self.current_run_file, 'r') as f:
                current_run = int(f.read().strip())

            run_dir = self.runs_dir / f"run_{current_run:03d}"

            return {
                'run_number': current_run,
                'run_directory': str(run_dir),
                'exists': run_dir.exists()
            }

        except Exception as e:
            print(f"âš ï¸ ç²å–ç•¶å‰é‹è¡Œè³‡è¨Šå¤±æ•—: {e}")
            return None

    def is_valid_run(self, session_id):
        """æª¢æŸ¥æœƒè©±IDæ˜¯å¦æœ‰æ•ˆ"""
        try:
            if not session_id or not session_id.startswith('run_'):
                return False

            # ç›´æ¥ä½¿ç”¨ session_id ä½œç‚ºç›®éŒ„åï¼Œä¸é€²è¡Œæ•¸å­—è½‰æ›
            run_dir = self.runs_dir / session_id

            return run_dir.exists()
        except Exception as e:
            print(f"âš ï¸ æª¢æŸ¥æœƒè©±æœ‰æ•ˆæ€§å¤±æ•—: {e}")
            return False

    def get_run_directory(self, run_number):
        """ç²å–æŒ‡å®šé‹è¡Œçš„ç›®éŒ„è·¯å¾‘"""
        # è™•ç† run_number å¯èƒ½æ˜¯å­—ç¬¦ä¸²ï¼ˆå¦‚ "run_77"ï¼‰æˆ–æ•´æ•¸çš„æƒ…æ³
        if isinstance(run_number, str):
            if run_number.startswith('run_'):
                # å¦‚æœå·²ç¶“æ˜¯ "run_XXX" æ ¼å¼ï¼Œç›´æ¥ä½¿ç”¨
                run_dir = self.runs_dir / run_number
            else:
                # å¦‚æœæ˜¯ç´”æ•¸å­—å­—ç¬¦ä¸²ï¼Œè½‰æ›ç‚ºæ•´æ•¸å¾Œæ ¼å¼åŒ–
                try:
                    num = int(run_number)
                    run_dir = self.runs_dir / f"run_{num:03d}"
                except ValueError:
                    # å¦‚æœç„¡æ³•è½‰æ›ï¼Œç›´æ¥ä½¿ç”¨åŸå­—ç¬¦ä¸²
                    run_dir = self.runs_dir / f"run_{run_number}"
        else:
            # å¦‚æœæ˜¯æ•´æ•¸ï¼Œæ­£å¸¸æ ¼å¼åŒ–
            run_dir = self.runs_dir / f"run_{run_number:03d}"
        return str(run_dir)

    def list_all_runs(self):
        """åˆ—å‡ºæ‰€æœ‰é‹è¡Œ"""
        runs = []

        try:
            if self.history_file.exists():
                with open(self.history_file, 'r', encoding='utf-8') as f:
                    history = json.load(f)

                for record in history:
                    run_dir = Path(record['run_directory'])
                    record['directory_exists'] = run_dir.exists()

                    if run_dir.exists():
                        # çµ±è¨ˆæª”æ¡ˆæ•¸é‡
                        record['file_counts'] = {}
                        for subdir in ['upload', 'alignment', 'segmentation', 'matching', 'detection']:
                            subdir_path = run_dir / subdir
                            if subdir_path.exists():
                                file_count = len([f for f in subdir_path.rglob('*') if f.is_file()])
                                record['file_counts'][subdir] = file_count

                    runs.append(record)

        except Exception as e:
            print(f"âš ï¸ åˆ—å‡ºé‹è¡Œå¤±æ•—: {e}")

        return runs

# ğŸ”§ åˆå§‹åŒ–é‹è¡Œç®¡ç†å™¨
run_manager = RunManager(app.config['RESULTS_FOLDER'])

# å…¨åŸŸè®Šæ•¸å„²å­˜å·¥ä½œéšæ®µè³‡æ–™
session_data = {}

# ğŸ”§ æ–°å¢ï¼šNumPy æ•¸æ“šé¡å‹è½‰æ›å‡½å¼
def convert_numpy_types(obj):
    """éæ­¸è½‰æ› NumPy æ•¸æ“šé¡å‹ç‚º Python åŸç”Ÿé¡å‹"""
    if isinstance(obj, np.integer):
        return int(obj)
    elif isinstance(obj, np.floating):
        return float(obj)
    elif isinstance(obj, np.ndarray):
        return obj.tolist()
    elif isinstance(obj, dict):
        return {key: convert_numpy_types(value) for key, value in obj.items()}
    elif isinstance(obj, list):
        return [convert_numpy_types(item) for item in obj]
    elif isinstance(obj, tuple):
        return tuple(convert_numpy_types(item) for item in obj)
    elif hasattr(obj, 'item'):  # è™•ç†å…¶ä»– NumPy æ¨™é‡é¡å‹
        return obj.item()
    else:
        return obj

@app.route('/api/health', methods=['GET'])
def health_check():
    """ç³»çµ±å¥åº·æª¢æŸ¥"""
    return create_success_response({'status': 'healthy', 'timestamp': datetime.now().isoformat()})

# ===== ğŸ”§ æ–°å¢ï¼šé‹è¡Œç®¡ç†ç›¸é—œ API =====

@app.route('/api/start_new_run', methods=['POST'])
def start_new_run():
    """é–‹å§‹æ–°çš„é‹è¡Œ"""
    try:
        run_dir, run_number = run_manager.create_run_directory()

        return create_success_response({
            'run_number': run_number,
            'run_directory': run_dir,
            'message': f'é–‹å§‹ç¬¬ {run_number} æ¬¡é‹è¡Œ'
        })

    except Exception as e:
        return create_error_response(f'é–‹å§‹æ–°é‹è¡Œå¤±æ•—: {str(e)}', 500)

@app.route('/api/runs', methods=['GET'])
def list_runs():
    """åˆ—å‡ºæ‰€æœ‰é‹è¡Œ"""
    try:
        runs = run_manager.list_all_runs()
        return create_success_response({
            'runs': runs,
            'total_runs': len(runs)
        })
    except Exception as e:
        return create_error_response(f'åˆ—å‡ºé‹è¡Œå¤±æ•—: {str(e)}', 500)

# ===== ğŸ•’ æ­·å²å›é¡§ API =====
@app.route('/api/history/runs', methods=['GET'])
def get_history_runs():
    """å–å¾—æ­·å²åˆ†æç¸®åœ–åˆ—è¡¨"""
    try:
        runs_dir = Path(app.config['RESULTS_FOLDER']) / 'runs'
        if not runs_dir.exists():
            return jsonify({'runs': []})

        runs = []
        for run_name in sorted(os.listdir(runs_dir)):
            run_path = runs_dir / run_name
            if not run_path.is_dir():
                continue

            # æª¢æŸ¥ upload ç›®éŒ„ä¸­çš„ image1 å’Œ image2
            upload_path = run_path / 'upload'
            image1_path = None
            image2_path = None

            if upload_path.exists():
                # å°‹æ‰¾ image1 å’Œ image2 æª”æ¡ˆ
                for file in upload_path.glob('*'):
                    if file.is_file() and file.suffix.lower() in ['.jpg', '.jpeg', '.png']:
                        filename_lower = file.name.lower()
                        if 'image1' in filename_lower or filename_lower.startswith('1_') or filename_lower.endswith('_1.jpg') or filename_lower.endswith('_1.jpeg') or filename_lower.endswith('_1.png'):
                            image1_path = f'/api/files/{run_name}/upload/{file.name}'
                        elif 'image2' in filename_lower or filename_lower.startswith('2_') or filename_lower.endswith('_2.jpg') or filename_lower.endswith('_2.jpeg') or filename_lower.endswith('_2.png'):
                            image2_path = f'/api/files/{run_name}/upload/{file.name}'

                # å¦‚æœæ²’æ‰¾åˆ°ç‰¹å®šå‘½åï¼Œå°±å–å‰å…©å€‹åœ–ç‰‡æª”æ¡ˆ
                if not image1_path and not image2_path:
                    image_files = sorted([f for f in upload_path.glob('*') if f.is_file() and f.suffix.lower() in ['.jpg', '.jpeg', '.png']])
                    if len(image_files) >= 1:
                        image1_path = f'/api/files/{run_name}/upload/{image_files[0].name}'
                    if len(image_files) >= 2:
                        image2_path = f'/api/files/{run_name}/upload/{image_files[1].name}'

            # å¦‚æœæ‰¾åˆ°åœ–ç‰‡ï¼ŒåŠ å…¥åˆ—è¡¨
            if image1_path or image2_path:
                runs.append({
                    'run_id': run_name,
                    'image1_url': image1_path,
                    'image2_url': image2_path
                })

        return jsonify({'runs': runs})
    except Exception as e:
        return create_error_response(f'å–å¾—æ­·å²é‹è¡Œå¤±æ•—: {str(e)}', 500)

@app.route('/api/history/run/<run_id>', methods=['GET'])
def get_history_run_detail(run_id):
    """å–å¾—æŒ‡å®šæ­·å²åˆ†æè©³ç´°çµæœ"""
    try:
        run_path = Path(app.config['RESULTS_FOLDER']) / 'runs' / run_id
        result_file = run_path / 'result.json'

        # å¦‚æœ result.json å­˜åœ¨ï¼Œç›´æ¥è®€å–
        if result_file.exists():
            with open(result_file, 'r', encoding='utf-8') as f:
                result = json.load(f)
            return jsonify(result)

        # å¦‚æœæ²’æœ‰ result.jsonï¼Œå˜—è©¦å¾ç¾æœ‰æª”æ¡ˆé‡å»ºçµæœ
        print(f"ğŸ” é‡å»º {run_id} çš„åˆ†æçµæœ...")

        # æª¢æŸ¥å¿…è¦çš„ç›®éŒ„
        upload_dir = run_path / 'upload'
        detection_dir = run_path / 'detection'

        if not upload_dir.exists():
            return create_error_response('æ‰¾ä¸åˆ°ä¸Šå‚³æª”æ¡ˆ', 404)

        # é‡å»ºåŸºæœ¬çµæœçµæ§‹
        rebuild_result = {
            'run_id': run_id,
            'timestamp': datetime.now().isoformat(),
            'generated_images': [],
            'separated_images': [],
            'output_directory': str(detection_dir) if detection_dir.exists() else '',
            'mask_folders': [],
            'statistics': {},
            'report_path': '',
            'disappeared_objects': [],
            'appeared_objects': [],
            'same_objects': [],
            'visualization_images': []
        }

        # å¦‚æœæœ‰æª¢æ¸¬çµæœï¼Œå˜—è©¦é‡å»ºç‰©ä»¶è³‡æ–™
        if detection_dir.exists():
            try:
                objects_data = generate_objects_data({'success': True}, detection_dir)
                rebuild_result['disappeared_objects'] = objects_data['disappeared']
                rebuild_result['appeared_objects'] = objects_data['appeared']

                # æŸ¥æ‰¾ç”Ÿæˆçš„åœ–ç‰‡
                for img_file in detection_dir.glob('*.jpg'):
                    img_path = f'/api/files/{run_id}/detection/{img_file.name}'
                    rebuild_result['generated_images'].append(img_path)
                    rebuild_result['visualization_images'].append({
                        'title': img_file.stem.replace('_', ' ').title(),
                        'description': f'æª¢æ¸¬çµæœåœ–ç‰‡: {img_file.name}',
                        'path': img_path
                    })

            except Exception as e:
                print(f"âš ï¸ é‡å»ºç‰©ä»¶è³‡æ–™å¤±æ•—: {e}")

        # ä¿å­˜é‡å»ºçš„çµæœä¾›ä¸‹æ¬¡ä½¿ç”¨
        with open(result_file, 'w', encoding='utf-8') as f:
            json.dump(rebuild_result, f, indent=2, ensure_ascii=False)
        print(f"ğŸ’¾ é‡å»ºçµæœå·²ä¿å­˜åˆ°: {result_file}")

        return jsonify(rebuild_result)

    except Exception as e:
        return create_error_response(f'å–å¾—åˆ†æçµæœå¤±æ•—: {str(e)}', 500)

@app.route('/api/run/<int:run_number>', methods=['GET'])
def get_run_details(run_number):
    """ç²å–ç‰¹å®šé‹è¡Œçš„è©³ç´°è³‡è¨Š"""
    try:
        runs = run_manager.list_all_runs()
        run_info = next((r for r in runs if r['run_number'] == run_number), None)

        if not run_info:
            return create_error_response('æ‰¾ä¸åˆ°æŒ‡å®šçš„é‹è¡Œ', 404)

        return create_success_response(run_info)

    except Exception as e:
        return create_error_response(f'ç²å–é‹è¡Œè©³ç´°è³‡è¨Šå¤±æ•—: {str(e)}', 500)

@app.route('/api/current_run', methods=['GET'])
def get_current_run():
    """ç²å–ç•¶å‰é‹è¡Œç·¨è™Ÿ"""
    try:
        current_run = run_manager.get_current_run_info()

        if not current_run or not current_run.get('exists', False):
            return create_success_response({
                'run_number': None,
                'message': 'ç›®å‰æ²’æœ‰æ´»èºçš„é‹è¡Œ'
            })

        return create_success_response({
            'run_number': current_run['run_number'],
            'run_directory': current_run['run_directory'],
            'exists': current_run['exists']
        })

    except Exception as e:
        return create_error_response(f'ç²å–ç•¶å‰é‹è¡Œå¤±æ•—: {str(e)}', 500)

# ===== ğŸ¥ æ–°å¢ï¼šå½±ç‰‡è™•ç†ç›¸é—œ API =====

@app.route('/api/extract_frames', methods=['POST'])
def extract_frames():
    """å¾å½±ç‰‡æå–å½±æ ¼"""
    try:
        if 'video' not in request.files:
            return create_error_response('æœªæä¾›å½±ç‰‡æª”æ¡ˆ', 400)

        video_file = request.files['video']
        if video_file.filename == '':
            return create_error_response('æœªé¸æ“‡æª”æ¡ˆ', 400)

        # ç²å–åƒæ•¸
        interval_seconds = float(request.form.get('interval', 1.0))
        max_frames = int(request.form.get('max_frames', 50))
        session_id = request.form.get('session_id')  # ğŸ”§ æ–°å¢ï¼šæª¢æŸ¥æ˜¯å¦æœ‰ç¾æœ‰æœƒè©±

        print(f"ğŸ“¹ é–‹å§‹è™•ç†å½±ç‰‡: {video_file.filename}")
        print(f"â° æå–é–“éš”: {interval_seconds}ç§’, æœ€å¤§å½±æ ¼æ•¸: {max_frames}")
        print(f"ğŸ” æª¢æŸ¥ç¾æœ‰æœƒè©±: {session_id}")

        # ğŸ”§ ä¿®æ­£ï¼šå„ªå…ˆä½¿ç”¨ç¾æœ‰æœƒè©±ï¼Œå¦å‰‡å‰µå»ºæ–°æœƒè©±
        if session_id and run_manager.is_valid_run(session_id):
            run_dir = run_manager.get_run_directory(session_id)
            run_number = int(session_id.replace('run_', ''))
            print(f"ğŸ”„ é‡ç”¨ç¾æœ‰æœƒè©±: {session_id}")
        else:
            run_dir, run_number = run_manager.create_run_directory()
            session_id = f'run_{run_number:03d}'  # ğŸ”§ ä½¿ç”¨3ä½æ•¸æ ¼å¼ä¿æŒä¸€è‡´
            print(f"ğŸ†• å‰µå»ºæ–°æœƒè©±: {session_id}")

        # å‰µå»ºå½±ç‰‡è™•ç†ç›®éŒ„
        video_dir = Path(run_dir) / 'video_processing'
        video_dir.mkdir(exist_ok=True)

        # å„²å­˜å½±ç‰‡æª”æ¡ˆ
        video_filename = f"input_video_{datetime.now().strftime('%Y%m%d_%H%M%S')}.{video_file.filename.split('.')[-1]}"
        video_path = video_dir / video_filename
        video_file.save(str(video_path))

        print(f"ğŸ’¾ å½±ç‰‡å·²å„²å­˜: {video_path}")

        # è™•ç†å½±ç‰‡
        result = extract_video_frames_api(
            str(video_path),
            str(video_dir),
            interval_seconds,
            max_frames
        )

        if result['success']:
            # æ›´æ–°é‹è¡Œç‹€æ…‹
            run_manager.update_run_status(run_number, 'video_processing', 'completed')

            # ğŸ¯ ç°¡åŒ–å›æ‡‰ï¼šå°ˆæ³¨æ–¼å½±æ ¼æå–çµæœ
            response_data = {
                'session_id': session_id,  # ğŸ”§ æ–°å¢ï¼šè¿”å›æœƒè©±ID
                'run_number': run_number,
                'video_info': result['video_info'],
                'extracted_frames': len(result['frames']),
                'frames_directory': result['output_dir'],
                'frames': result['frames'],  # å®Œæ•´çš„å½±æ ¼åˆ—è¡¨
                'message': f'æˆåŠŸæå– {len(result["frames"])} å€‹å½±æ ¼ï¼Œç¾åœ¨å¯ä»¥é¸æ“‡ä»»æ„2å€‹å½±æ ¼é€²è¡Œè®ŠåŒ–æª¢æ¸¬'
            }

            print(f"âœ… å½±ç‰‡è™•ç†å®Œæˆ: æå–äº† {len(result['frames'])} å€‹å½±æ ¼")
            print(f"ğŸ“ å½±æ ¼å­˜æ”¾ä½ç½®: {result['output_dir']}")

            return create_success_response(response_data, 'å½±æ ¼æå–å®Œæˆï¼Œå¯é–‹å§‹é¸æ“‡å½±æ ¼é€²è¡Œåˆ†æ')
        else:
            return create_error_response(result['error'], 500)

    except Exception as e:
        print(f"âŒ å½±ç‰‡è™•ç†éŒ¯èª¤: {str(e)}")
        traceback.print_exc()
        return create_error_response(f'å½±ç‰‡è™•ç†å¤±æ•—: {str(e)}', 500)

@app.route('/api/video_frames/<int:run_number>', methods=['GET'])
def get_video_frames(run_number):
    """ç²å–æŒ‡å®šé‹è¡Œçš„å½±ç‰‡å½±æ ¼åˆ—è¡¨"""
    try:
        run_dir = Path(app.config['RESULTS_FOLDER']) / 'runs' / f'run_{run_number:03d}'
        frames_dir = run_dir / 'video_processing' / 'frames'

        if not frames_dir.exists():
            return create_error_response('æ‰¾ä¸åˆ°å½±ç‰‡å½±æ ¼ç›®éŒ„', 404)

        # ç²å–æ‰€æœ‰å½±æ ¼æª”æ¡ˆ
        frame_files = sorted([
            f for f in frames_dir.iterdir()
            if f.is_file() and f.suffix.lower() in ['.jpg', '.jpeg', '.png']
        ])

        frames_info = []
        for i, frame_file in enumerate(frame_files):
            # å¾æª”åè§£ææ™‚é–“æˆ³
            filename = frame_file.name
            timestamp = 0.0
            if '_t' in filename and 's.' in filename:
                try:
                    timestamp_str = filename.split('_t')[1].split('s.')[0]
                    timestamp = float(timestamp_str)
                except:
                    pass

            frames_info.append({
                'index': i,
                'filename': filename,
                'path': str(frame_file),
                'timestamp': timestamp,
                'url': f'/api/files/run_{run_number:03d}/video_processing/frames/{filename}'
            })

        return create_success_response({
            'run_number': run_number,
            'total_frames': len(frames_info),
            'frames': frames_info
        })

    except Exception as e:
        return create_error_response(f'ç²å–å½±æ ¼åˆ—è¡¨å¤±æ•—: {str(e)}', 500)

@app.route('/api/upload', methods=['POST'])
def upload_files():
    try:
        print("ğŸš€ é–‹å§‹è™•ç†æª”æ¡ˆä¸Šå‚³...")

        # ğŸ”§ æ–°å¢ï¼šæª¢æŸ¥æ˜¯å¦æœ‰å‚³å…¥ç¾æœ‰çš„session_id
        existing_session_id = request.form.get('session_id')
        print(f"ğŸ” æ”¶åˆ°çš„ session_id: {existing_session_id}")

        if existing_session_id:
            print(f"ğŸ” æª¢æŸ¥æœƒè©±æœ‰æ•ˆæ€§: {run_manager.is_valid_run(existing_session_id)}")

        if existing_session_id and run_manager.is_valid_run(existing_session_id):
            # é‡ç”¨ç¾æœ‰çš„run
            run_dir = run_manager.get_run_directory(existing_session_id)
            # ğŸ”§ ç›´æ¥ä½¿ç”¨åŸå§‹çš„session_idï¼Œä¸é‡æ–°æ ¼å¼åŒ–
            session_id = existing_session_id
            # å¾session_idæå–æ•¸å­—ç”¨æ–¼update_run_status
            run_number = int(existing_session_id.replace('run_', ''))
            print(f"â™»ï¸ é‡ç”¨ç¾æœ‰é‹è¡Œ: {session_id}")
            print(f"ğŸ“ é‹è¡Œç›®éŒ„: {run_dir}")
        else:
            # å‰µå»ºæ–°çš„run
            run_dir, run_number = run_manager.create_run_directory()
            session_id = f"run_{run_number:03d}"
            print(f"âœ… å‰µå»ºæ–°é‹è¡Œ: {session_id}")
            print(f"ğŸ“ é‹è¡Œç›®éŒ„: {run_dir}")

        # ç²å–ä¸Šå‚³ç›®éŒ„
        upload_dir = os.path.join(run_dir, "upload")

        # è™•ç†æª”æ¡ˆä¸Šå‚³
        ref_image = request.files.get('ref_image')
        input_image = request.files.get('input_image')

        if not ref_image or not input_image:
            raise ValueError('éœ€è¦å…©å€‹åœ–ç‰‡æª”æ¡ˆ')

        # ğŸ”§ é—œéµä¿®æ”¹ï¼šç°¡åŒ–æª”åç‚º image1.jpg å’Œ image2.jpg
        ref_filename = "image1.jpg"
        input_filename = "image2.jpg"

        # å„²å­˜æª”æ¡ˆ
        ref_path = os.path.join(upload_dir, ref_filename)
        input_path = os.path.join(upload_dir, input_filename)

        ref_image.save(ref_path)
        input_image.save(input_path)

        # ğŸ”§ æ›´æ–°æˆ–å‰µå»º session_data
        if session_id not in session_data:
            session_data[session_id] = {}

        session_data[session_id].update({
            'run_number': run_number,
            'run_directory': run_dir,
            'ref_image': {
                'filename': ref_filename,
                'path': ref_path
            },
            'input_image': {
                'filename': input_filename,
                'path': input_path
            }
        })

        # æ›´æ–°é‹è¡Œç‹€æ…‹
        run_manager.update_run_status(run_number, 'upload', 'completed')

        print(f"ğŸ“¤ æª”æ¡ˆå„²å­˜è‡³: {upload_dir}")
        print(f"  - {ref_filename}")
        print(f"  - {input_filename}")
        print(f"ğŸ”‘ session_id: {session_id}")

        return jsonify({
            'status': 'success',
            'message': 'æª”æ¡ˆä¸Šå‚³æˆåŠŸ',
            'session_id': session_id,
            'run_id': session_id,
            'upload_directory': upload_dir,
            'files': {
                'ref_image': ref_filename,
                'input_image': input_filename,
                'ref_path': ref_path,
                'input_path': input_path
            }
        })

    except Exception as e:
        print(f"âŒ ä¸Šå‚³å¤±æ•—: {str(e)}")
        import traceback
        traceback.print_exc()
        return jsonify({
            'status': 'error',
            'message': str(e)
        }), 500

@app.route('/api/align', methods=['POST'])
def align_images():
    """åœ–åƒå°é½Šç«¯é» - æ•´åˆé‹è¡Œç®¡ç†"""
    try:
        print("=" * 60)
        print("ğŸ“ åœ–åƒå°é½Š API è¢«èª¿ç”¨")
        print(f"â° æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        data = request.get_json()
        print(f"ğŸ“ æ¥æ”¶åƒæ•¸: {data}")

        session_id = data.get('session_id')
        print(f"ğŸ”‘ æŸ¥è©¢å·¥ä½œéšæ®µ ID: {session_id}")

        # ğŸ”§ ä¿®æ­£ï¼šæª¢æŸ¥ session_data ä¸­æ˜¯å¦æœ‰è©² session_id
        if session_id not in session_data:
            print(f"âŒ å¯ç”¨çš„ session_id: {list(session_data.keys())}")
            return create_error_response(f'ç„¡æ•ˆçš„å·¥ä½œéšæ®µID: {session_id}', 400)

        session = session_data[session_id]
        run_number = session.get('run_number')
        run_dir = session.get('run_directory')

        print(f"ğŸ”¢ é‹è¡Œç·¨è™Ÿ: {run_number}")
        print(f"ğŸ“ é‹è¡Œç›®éŒ„: {run_dir}")

        # ğŸ”§ è¨­å®šè¼¸å‡ºåˆ°ç•¶å‰é‹è¡Œçš„ alignment ç›®éŒ„
        output_dir = Path(run_dir) / 'alignment'
        output_dir.mkdir(parents=True, exist_ok=True)
        print(f"ğŸ“ å°é½Šè¼¸å‡ºç›®éŒ„: {output_dir}")

        # ğŸ”§ ä¿®æ­£ï¼šå¾ session ä¸­ç²å–æª”æ¡ˆè·¯å¾‘
        ref_path = session['ref_image']['path']
        input_path = session['input_image']['path']

        print(f"ğŸ“ åƒè€ƒåœ–åƒ: {ref_path}")
        print(f"ğŸ“ è¼¸å…¥åœ–åƒ: {input_path}")

        if not os.path.exists(ref_path) or not os.path.exists(input_path):
            return create_error_response('åœ–åƒæª”æ¡ˆä¸å­˜åœ¨æ–¼ä¼ºæœå™¨', 400)

        # åŸ·è¡Œå°é½Š
        print("ğŸš€ é–‹å§‹åŸ·è¡Œåœ–åƒå°é½Š...")
        result = align_images_api(
            ref_path, input_path, str(output_dir),
            data.get('pyramid_levels', 4),
            data.get('motion_type', 'EUCLIDEAN')
        )

        # ğŸ”§ æ›´æ–°é‹è¡Œç‹€æ…‹
        if result.get('status') == 'success':
            files_info = [f"aligned_image: {Path(output_dir).name}"]
            run_manager.update_run_status(run_number, 'alignment', 'completed', files_info)
            print(f"âœ… é‹è¡Œç‹€æ…‹å·²æ›´æ–° - å°é½Šå®Œæˆ")

        print(f"ğŸ“Š å°é½Šçµæœç‹€æ…‹: {result.get('status')}")
        print("=" * 60)

        serializable_result = convert_numpy_types(result)
        return jsonify(serializable_result)

    except Exception as e:
        print("=" * 60)
        print(f"ğŸ’¥ åœ–åƒå°é½Šç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        traceback.print_exc()
        print("=" * 60)
        return create_error_response(f'åœ–åƒå°é½Šå¤±æ•—: {str(e)}', 500)

@app.route('/api/remove_sky', methods=['POST'])
def remove_sky():
    """å¤©ç©ºé®ç½©å»é™¤ç«¯é» - ä¿®æ­£ç‰ˆï¼šæ­£ç¢ºä½¿ç”¨åœ–ç‰‡1å’Œåœ–ç‰‡2"""
    try:
        print("=" * 60)
        print("ğŸŒ¤ï¸ å¤©ç©ºé®ç½©å»é™¤ API è¢«èª¿ç”¨")
        print(f"â° æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        data = request.get_json()
        session_id = data.get('session_id')
        enable_sky_removal = data.get('enable_sky_removal', True)  # ğŸ”§ æ–°å¢ï¼šå¤©ç©ºé®ç½©å»é™¤é–‹é—œ

        print(f"ğŸ”§ å¤©ç©ºé®ç½©å»é™¤è¨­å®š: {enable_sky_removal}")

        if session_id not in session_data:
            return create_error_response('ç„¡æ•ˆçš„å·¥ä½œéšæ®µID', 400)

        session = session_data[session_id]
        run_number = session.get('run_number')
        run_dir = session.get('run_directory')

        # è¨­å®šè¼¸å‡ºç›®éŒ„
        output_dir = Path(run_dir) / 'sky_removal'
        output_dir.mkdir(parents=True, exist_ok=True)

        # ğŸ”§ é—œéµä¿®æ­£ï¼šåˆ†åˆ¥å–å¾—åœ–ç‰‡1å’Œåœ–ç‰‡2ï¼Œä¸è¦æ··ç”¨
        input_image_paths = []

        # å„ªå…ˆä½¿ç”¨å°é½Šå¾Œçš„åœ–ç‰‡ï¼Œä½†è¦ç¢ºä¿æ˜¯æ­£ç¢ºçš„å°æ‡‰é—œä¿‚
        alignment_dir = Path(run_dir) / 'alignment'

        if alignment_dir.exists():
            # ğŸ”§ ä¿®æ­£ï¼šå°‹æ‰¾å°é½Šå¾Œçš„åœ–ç‰‡ï¼Œç¢ºä¿èˆ‡åŸå§‹åœ–ç‰‡å°æ‡‰
            ref_image_name = Path(session['ref_image']['filename']).stem  # åœ–ç‰‡1æª”å
            input_image_name = Path(session['input_image']['filename']).stem  # åœ–ç‰‡2æª”å

            print(f"ğŸ“‹ å°‹æ‰¾å°æ‡‰çš„å°é½Šåœ–ç‰‡:")
            print(f"  - åœ–ç‰‡1åŸæª”å: {ref_image_name}")
            print(f"  - åœ–ç‰‡2åŸæª”å: {input_image_name}")

            # å°‹æ‰¾å°æ‡‰çš„å°é½Šçµæœ
            aligned_image1_path = None
            aligned_image2_path = None

            for ext in ['*.jpg', '*.jpeg', '*.png']:
                for aligned_file in alignment_dir.glob(ext):
                    file_name = aligned_file.stem
                    # ğŸ”§ æ›´ç²¾ç¢ºçš„æª”æ¡ˆåŒ¹é…é‚è¼¯
                    if file_name == 'aligned_image':  # ç²¾ç¢ºåŒ¹é…å°é½Šå¾Œçš„åœ–ç‰‡
                        aligned_image2_path = str(aligned_file)
                        print(f"  âœ… æ‰¾åˆ°åœ–ç‰‡2å°é½Šçµæœ: {aligned_file.name}")
                    elif ref_image_name in file_name and 'aligned' not in file_name.lower():
                        # åƒè€ƒåœ–ç‰‡çš„å°é½Šç‰ˆæœ¬ï¼ˆé€šå¸¸åƒè€ƒåœ–ç‰‡ä¸æœƒè¢«å°é½Šï¼‰
                        aligned_image1_path = str(aligned_file)
                        print(f"  âœ… æ‰¾åˆ°åœ–ç‰‡1å°é½Šçµæœ: {aligned_file.name}")

            # ğŸ”§ å¦‚æœæ‰¾åˆ°å°é½Šçµæœï¼Œä½¿ç”¨å°é½Šå¾Œçš„åœ–ç‰‡
            if aligned_image1_path and aligned_image2_path:
                input_image_paths = [aligned_image1_path, aligned_image2_path]
                print("ğŸ“ âœ… ä½¿ç”¨å°é½Šå¾Œçš„åœ–ç‰‡é€²è¡Œå¤©ç©ºå»é™¤")
            else:
                # ğŸ”§ å›é€€ï¼šå°‹æ‰¾ aligned_image æ–‡ä»¶
                aligned_image_file = None
                for ext in ['*.jpg', '*.jpeg', '*.png']:
                    potential_files = list(alignment_dir.glob(f'aligned_image.{ext[2:]}'))
                    if potential_files:
                        aligned_image_file = potential_files[0]
                        break

                if aligned_image_file:
                    # ä½¿ç”¨åŸå§‹ref_image + å°é½Šå¾Œçš„input_image
                    input_image_paths = [
                        session['ref_image']['path'],      # åœ–ç‰‡1ï¼šä½¿ç”¨åŸå§‹æª”
                        str(aligned_image_file)            # åœ–ç‰‡2ï¼šä½¿ç”¨æ­£ç¢ºçš„å°é½Šæª”
                    ]
                    print(f"ğŸ“ âš ï¸ éƒ¨åˆ†å°é½Šï¼šåœ–ç‰‡1ä½¿ç”¨åŸæª”ï¼Œåœ–ç‰‡2ä½¿ç”¨å°é½Šç‰ˆæœ¬ ({aligned_image_file.name})")
                else:
                    input_image_paths = []
                    print("ğŸ“ âŒ æœªæ‰¾åˆ°æœ‰æ•ˆçš„å°é½Šæ–‡ä»¶")

        # ğŸ”§ æœ€çµ‚å›é€€ï¼šä½¿ç”¨åŸå§‹ä¸Šå‚³åœ–ç‰‡
        if not input_image_paths:
            input_image_paths = [
                session['ref_image']['path'],    # åœ–ç‰‡1
                session['input_image']['path']   # åœ–ç‰‡2
            ]
            print("ğŸ“¤ âš ï¸ å›é€€ä½¿ç”¨åŸå§‹ä¸Šå‚³åœ–ç‰‡")

        print(f"ğŸŒ¤ï¸ æœ€çµ‚ä½¿ç”¨çš„åœ–ç‰‡:")
        print(f"  - åœ–ç‰‡1 (image1): {Path(input_image_paths[0]).name}")
        print(f"  - åœ–ç‰‡2 (image2): {Path(input_image_paths[1]).name}")

        # ğŸ”§ é©—è­‰å…©å¼µåœ–ç‰‡ç¢ºå¯¦ä¸åŒ
        if Path(input_image_paths[0]).name == Path(input_image_paths[1]).name:
            print("âš ï¸ è­¦å‘Šï¼šå…©å¼µåœ–ç‰‡æª”åç›¸åŒï¼Œå¯èƒ½å­˜åœ¨é‡è¤‡ä½¿ç”¨å•é¡Œ")

        # åŸ·è¡Œå¤©ç©ºé®ç½©è™•ç†
        from modules.sky_removal import remove_sky_masks_api

        result = remove_sky_masks_api(
            image1_path=input_image_paths[0],  # ğŸ”§ ç¢ºä¿æ˜¯åœ–ç‰‡1
            image2_path=input_image_paths[1],  # ğŸ”§ ç¢ºä¿æ˜¯åœ–ç‰‡2
            output_dir=str(output_dir),
            device=data.get('device', 'auto'),
            enable_sky_removal=enable_sky_removal  # ğŸ”§ æ–°å¢ï¼šå‚³éå¤©ç©ºé®ç½©è¨­å®š
        )

        # ğŸ”§ æ›´æ–° session ä¸­çš„å¤©ç©ºå»é™¤åœ–ç‰‡è·¯å¾‘
        if result.get('status') == 'success':
            result_data = result.get('data', {})

            if 'sam2_ready_files' in result_data:
                sam2_files = result_data['sam2_ready_files']

                # ğŸ”§ ä¿®æ­£ï¼šç¢ºä¿æ­£ç¢ºå°æ‡‰é—œä¿‚
                if 'image1' in sam2_files and sam2_files['image1']:
                    session['sky_removed_image1'] = {
                        'filename': Path(sam2_files['image1']).name,
                        'path': sam2_files['image1']
                    }
                    print(f"âœ… å·²å„²å­˜å¤©ç©ºå»é™¤åœ–ç‰‡1: {session['sky_removed_image1']['filename']}")

                if 'image2' in sam2_files and sam2_files['image2']:
                    session['sky_removed_image2'] = {
                        'filename': Path(sam2_files['image2']).name,
                        'path': sam2_files['image2']
                    }
                    print(f"âœ… å·²å„²å­˜å¤©ç©ºå»é™¤åœ–ç‰‡2: {session['sky_removed_image2']['filename']}")

                # ğŸ”§ æœ€çµ‚é©—è­‰ï¼šç¢ºä¿å…©å¼µå¤©ç©ºå»é™¤åœ–ç‰‡ä¸åŒ
                if (session.get('sky_removed_image1', {}).get('filename') ==
                    session.get('sky_removed_image2', {}).get('filename')):
                    print("âŒ éŒ¯èª¤ï¼šå…©å¼µå¤©ç©ºå»é™¤åœ–ç‰‡æª”åç›¸åŒï¼")
                else:
                    print("âœ… ç¢ºèªï¼šå…©å¼µå¤©ç©ºå»é™¤åœ–ç‰‡æª”åä¸åŒ")

            # æ›´æ–°é‹è¡Œç‹€æ…‹
            run_manager.update_run_status(run_number, 'sky_removal', 'completed')

        return jsonify(convert_numpy_types(result))

    except Exception as e:
        print(f"ğŸ’¥ å¤©ç©ºé®ç½©å»é™¤éŒ¯èª¤: {str(e)}")
        traceback.print_exc()
        return create_error_response(f'å¤©ç©ºé®ç½©å»é™¤å¤±æ•—: {str(e)}', 500)

@app.route('/api/segment', methods=['POST'])
def segment_images():
    """SAM2 èªæ„åˆ†å‰²ç«¯é» - ä½¿ç”¨å¤©ç©ºå»é™¤å¾Œçš„åœ–ç‰‡ä¸¦å›å‚³ä½¿ç”¨çš„åœ–ç‰‡"""
    try:
        print("=" * 60)
        print("ğŸ¤– SAM2 åˆ†å‰² API è¢«èª¿ç”¨")
        print(f"â° æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        data = request.get_json()
        session_id = data.get('session_id')

        if session_id not in session_data:
            return create_error_response('ç„¡æ•ˆçš„å·¥ä½œéšæ®µID', 400)

        session = session_data[session_id]
        run_number = session.get('run_number')
        run_dir = session.get('run_directory')

        print(f"ğŸ”¢ é‹è¡Œç·¨è™Ÿ: {run_number}")

        # ğŸ”§ è¨­å®šè¼¸å‡ºåˆ°ç•¶å‰é‹è¡Œçš„ segmentation ç›®éŒ„
        output_dir = Path(run_dir) / 'segmentation'
        output_dir.mkdir(parents=True, exist_ok=True)
        print(f"ğŸ“ åˆ†å‰²è¼¸å‡ºç›®éŒ„: {output_dir}")

        # ğŸ”§ é—œéµä¿®æ­£ï¼šå„ªå…ˆä½¿ç”¨ session ä¸­ä¿å­˜çš„å¤©ç©ºå»é™¤åœ–ç‰‡è·¯å¾‘
        image_paths = []
        current_image_info = []

        # ğŸ”§ å„ªå…ˆä½¿ç”¨ session ä¸­ä¿å­˜çš„å¤©ç©ºå»é™¤åœ–ç‰‡
        sky_removed_image1 = session.get('sky_removed_image1', {})
        sky_removed_image2 = session.get('sky_removed_image2', {})

        if sky_removed_image1.get('path') and sky_removed_image2.get('path'):
            # ä½¿ç”¨ session ä¸­ä¿å­˜çš„å¤©ç©ºè™•ç†å¾Œåœ–ç‰‡
            image_paths = [sky_removed_image1['path'], sky_removed_image2['path']]
            current_image_info = [
                {
                    'source': 'sky_processed',
                    'filename': sky_removed_image1['filename'],
                    'path': sky_removed_image1['path']
                },
                {
                    'source': 'sky_processed',
                    'filename': sky_removed_image2['filename'],
                    'path': sky_removed_image2['path']
                }
            ]
            print("ğŸŒ¤ï¸ âœ… ä½¿ç”¨ session ä¸­çš„å¤©ç©ºè™•ç†åœ–ç‰‡é€²è¡Œåˆ†å‰²")
            print(f"  - åœ–ç‰‡1: {sky_removed_image1['filename']}")
            print(f"  - åœ–ç‰‡2: {sky_removed_image2['filename']}")
        else:
            # ğŸ”§ å›é€€ï¼šå¾ sky_removal ç›®éŒ„ä¸­å°‹æ‰¾ SAM2 å°ˆç”¨çš„åœ–ç‰‡
            sky_removal_dir = Path(run_dir) / 'sky_removal'
            image1_sam2_path = sky_removal_dir / 'image1_sam2_ready.png'
            image2_sam2_path = sky_removal_dir / 'aligned_image_sam2_ready.png'

            print(f"ğŸ” æª¢æŸ¥å¤©ç©ºå»é™¤ç›®éŒ„åœ–ç‰‡:")
            print(f"  - åœ–ç‰‡1: {image1_sam2_path}")
            print(f"  - åœ–ç‰‡2: {image2_sam2_path}")

            if image1_sam2_path.exists() and image2_sam2_path.exists():
                image_paths = [str(image1_sam2_path), str(image2_sam2_path)]
                current_image_info = [
                    {
                        'source': 'sky_removed_directory',
                        'filename': image1_sam2_path.name,
                        'path': str(image1_sam2_path)
                    },
                    {
                        'source': 'sky_removed_directory',
                        'filename': image2_sam2_path.name,
                        'path': str(image2_sam2_path)
                    }
                ]
                print("ğŸŒ¤ï¸ âš ï¸ ä½¿ç”¨å¤©ç©ºå»é™¤ç›®éŒ„çš„åœ–ç‰‡")
            else:
                # ğŸ”§ å¦‚æœæ²’æœ‰å¤©ç©ºå»é™¤ç‰ˆæœ¬ï¼Œå›é€€åˆ°å…¶ä»–ç‰ˆæœ¬
                print("âš ï¸ æœªæ‰¾åˆ°å¤©ç©ºå»é™¤åœ–ç‰‡ï¼Œæª¢æŸ¥å…¶ä»–ç‰ˆæœ¬...")

            # æª¢æŸ¥æ˜¯å¦æœ‰å°é½Šå¾Œçš„åœ–ç‰‡
            alignment_dir = Path(run_dir) / 'alignment'
            aligned_files = []

            if alignment_dir.exists():
                for ext in ['*.jpg', '*.jpeg', '*.png']:
                    aligned_files.extend(list(alignment_dir.glob(ext)))

            if len(aligned_files) >= 2:
                aligned_files.sort()
                image_paths = [str(aligned_files[0]), str(aligned_files[1])]
                current_image_info = [
                    {
                        'source': 'aligned',
                        'filename': aligned_files[0].name,
                        'path': str(aligned_files[0])
                    },
                    {
                        'source': 'aligned',
                        'filename': aligned_files[1].name,
                        'path': str(aligned_files[1])
                    }
                ]
                print("ğŸ“ âš ï¸ ä½¿ç”¨å°é½Šå¾Œçš„åœ–ç‰‡")
            else:
                # æœ€å¾Œå›é€€åˆ°åŸå§‹åœ–ç‰‡
                image_paths = [
                    session['ref_image']['path'],
                    session['input_image']['path']
                ]
                current_image_info = [
                    {
                        'source': 'original',
                        'filename': session['ref_image']['filename'],
                        'path': session['ref_image']['path']
                    },
                    {
                        'source': 'original',
                        'filename': session['input_image']['filename'],
                        'path': session['input_image']['path']
                    }
                ]
                print("ğŸ“¤ âš ï¸ å›é€€åˆ°åŸå§‹ä¸Šå‚³åœ–ç‰‡")

        # ğŸ†• åˆ†å‰²å‰å›å‚³ç•¶å‰ä½¿ç”¨çš„åœ–ç‰‡è³‡è¨Šä¸¦è¤‡è£½åˆ° segmentation ç›®éŒ„
        print(f"\nğŸ“¸ ç•¶å‰åˆ†å‰²ä½¿ç”¨çš„åœ–ç‰‡è³‡è¨Š:")
        for i, img_info in enumerate(current_image_info, 1):
            print(f"  åœ–ç‰‡{i}: {img_info['filename']} (ä¾†æº: {img_info['source']})")
            print(f"         è·¯å¾‘: {img_info['path']}")

            # æª¢æŸ¥æª”æ¡ˆæ˜¯å¦å­˜åœ¨
            if os.path.exists(img_info['path']):
                file_size = os.path.getsize(img_info['path'])
                print(f"         ç‹€æ…‹: âœ… å­˜åœ¨ ({file_size:,} bytes)")
            else:
                print(f"         ç‹€æ…‹: âŒ æª”æ¡ˆä¸å­˜åœ¨")

        # ğŸ†• è¤‡è£½ä½¿ç”¨çš„åœ–ç‰‡åˆ° segmentation ç›®éŒ„ä¸­
        copied_images = []
        for i, img_info in enumerate(current_image_info, 1):
            try:
                source_path = Path(img_info['path'])
                if source_path.exists():
                    # å‰µå»º image1_results å’Œ image2_results ç›®éŒ„
                    result_dir = output_dir / f"image{i}_results"
                    result_dir.mkdir(parents=True, exist_ok=True)

                    # è¤‡è£½åœ–ç‰‡åˆ°å°æ‡‰ç›®éŒ„
                    dest_path = result_dir / f"segmentation_input_{source_path.name}"
                    shutil.copy2(source_path, dest_path)

                    copied_images.append({
                        'image_index': i,
                        'source_path': str(source_path),
                        'copied_path': str(dest_path),
                        'source_type': img_info['source']
                    })

                    print(f"ğŸ“‹ å·²è¤‡è£½åœ–ç‰‡{i}åˆ°: {dest_path}")
                else:
                    print(f"âŒ ç„¡æ³•è¤‡è£½åœ–ç‰‡{i}ï¼šæºæª”æ¡ˆä¸å­˜åœ¨")
            except Exception as copy_error:
                print(f"âš ï¸ è¤‡è£½åœ–ç‰‡{i}å¤±æ•—: {copy_error}")

        # é©—è­‰åœ–ç‰‡æª”æ¡ˆå­˜åœ¨æ€§
        valid_images = []
        for img_path in image_paths:
            if os.path.exists(img_path):
                valid_images.append(img_path)
            else:
                print(f"âŒ è­¦å‘Šï¼šåœ–ç‰‡ä¸å­˜åœ¨ {img_path}")

        if len(valid_images) < 2:
            return create_error_response(f'åˆ†å‰²éœ€è¦è‡³å°‘2å¼µæœ‰æ•ˆåœ–ç‰‡ï¼Œç›®å‰åªæ‰¾åˆ°{len(valid_images)}å¼µ', 400)

        print(f"\nğŸ“Š æœ€çµ‚ä½¿ç”¨çš„åœ–ç‰‡æ•¸é‡: {len(valid_images)}")

        # åŸ·è¡Œåˆ†å‰²
        print("\nğŸš€ é–‹å§‹åŸ·è¡Œ SAM2 åˆ†å‰²...")
        start_time = datetime.now()

        try:
            if len(valid_images) == 1:
                result = segment_image_api(valid_images[0], str(output_dir))
            else:
                # ğŸ”§ ä½¿ç”¨å‰ç«¯å‚³ä¾†çš„åƒæ•¸é€²è¡Œåˆ†å‰²
                api_params = {
                    'checkpoint_path': None,  # ä½¿ç”¨é è¨­æ¨¡å‹
                    'device': data.get('device', 'auto'),
                    'save_individual_masks': True,
                    'enable_quality_enhancement': True
                }

                # ğŸ†• åŠ å…¥å‰ç«¯å‚³ä¾†çš„åˆ†å‰²åƒæ•¸
                segmentation_params = {}
                if 'points_per_side' in data:
                    segmentation_params['points_per_side'] = data['points_per_side']
                if 'points_per_batch' in data:
                    segmentation_params['points_per_batch'] = data['points_per_batch']
                if 'pred_iou_thresh' in data:
                    segmentation_params['pred_iou_thresh'] = data['pred_iou_thresh']
                if 'stability_score_thresh' in data:
                    segmentation_params['stability_score_thresh'] = data['stability_score_thresh']
                if 'stability_score_offset' in data:
                    segmentation_params['stability_score_offset'] = data['stability_score_offset']
                if 'min_mask_region_area' in data:
                    segmentation_params['min_mask_region_area'] = data['min_mask_region_area']

                print(f"ğŸ“‹ ä½¿ç”¨å‰ç«¯åƒæ•¸: {api_params}")
                print(f"ğŸ¯ åˆ†å‰²åƒæ•¸: {segmentation_params}")

                result = segment_multiple_images_api(
                    valid_images,
                    str(output_dir),
                    **api_params,
                    **segmentation_params
                )

            end_time = datetime.now()
            processing_time = (end_time - start_time).total_seconds()

            # ğŸ”§ åˆ†å‰²å®Œæˆå¾Œï¼Œå°‡åœ–ç‰‡ä¾†æºè³‡è¨Šå’Œè¤‡è£½è³‡è¨ŠåŠ å…¥çµæœ
            if result.get('status') == 'success' and result.get('data'):
                result['data']['images_used'] = current_image_info
                result['data']['processing_time'] = processing_time
                result['data']['copied_images'] = copied_images  # ğŸ†• åŠ å…¥è¤‡è£½çš„åœ–ç‰‡è³‡è¨Š

            # æ›´æ–°é‹è¡Œç‹€æ…‹
            if result.get('status') == 'success' or result.get('status') == 'partial_failure':
                total_masks = result.get('data', {}).get('total_masks_generated', 0)
                files_info = [
                    f"masks_generated: {total_masks}",
                    f"image_source: {current_image_info[0]['source']}",
                    f"copied_images: {len(copied_images)}"
                ]
                run_manager.update_run_status(run_number, 'segmentation', 'completed', files_info)
                print(f"âœ… é‹è¡Œç‹€æ…‹å·²æ›´æ–° - åˆ†å‰²å®Œæˆ")

            print(f"\nğŸ“Š SAM2 åˆ†å‰²å®Œæˆ:")
            print(f"  çµæœç‹€æ…‹: {result.get('status')}")
            print(f"  è™•ç†æ™‚é–“: {processing_time:.2f} ç§’")
            print(f"  ç”Ÿæˆé®ç½©: {result.get('data', {}).get('total_masks_generated', 0)} å€‹")
            print(f"  åœ–ç‰‡ä¾†æº: {current_image_info[0]['source']}")
            print(f"  è¤‡è£½åœ–ç‰‡: {len(copied_images)} å¼µ")

        except Exception as segment_error:
            print(f"ğŸ’¥ SAM2 åˆ†å‰²åŸ·è¡ŒéŒ¯èª¤: {segment_error}")
            raise segment_error

        print("=" * 60)

        serializable_result = convert_numpy_types(result)
        return jsonify(serializable_result)

    except Exception as e:
        print("=" * 60)
        print(f"ğŸ’¥ SAM2 åˆ†å‰²ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {str(e)}")
        traceback.print_exc()
        print("=" * 60)
        return create_error_response(f'SAM2 åˆ†å‰²å¤±æ•—: {str(e)}', 500)

@app.route('/api/match_masks', methods=['POST'])
def match_masks():
    """é®ç½©åŒ¹é…ç«¯é» - æ”¯æ´å–®æ¬¡åˆ†å‰²å’Œå…©æ¬¡åˆ†å‰²çš„çµ±ä¸€è™•ç†"""
    try:
        print("=" * 60)
        print("ğŸ­ é®ç½©åŒ¹é… API è¢«èª¿ç”¨")
        print(f"â° æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        data = request.get_json()
        session_id = data.get('session_id')

        if session_id not in session_data:
            return create_error_response('ç„¡æ•ˆçš„å·¥ä½œéšæ®µID', 400)

        session = session_data[session_id]
        run_number = session.get('run_number')
        run_dir = session.get('run_directory')

        print(f"ğŸ”¢ é‹è¡Œç·¨è™Ÿ: {run_number}")

        # è¨­å®šè¼¸å‡ºåˆ°ç•¶å‰é‹è¡Œçš„ matching ç›®éŒ„
        output_dir = Path(run_dir) / 'matching'
        output_dir.mkdir(parents=True, exist_ok=True)
        print(f"ğŸ“ åŒ¹é…è¼¸å‡ºç›®éŒ„: {output_dir}")

        # ğŸ”§ æ–°å¢å‡½æ•¸ï¼šçµ±ä¸€çš„é®ç½©ç›®éŒ„æŸ¥æ‰¾é‚è¼¯
        def find_mask_directories(segmentation_dir):
            """æŸ¥æ‰¾ä¸¦é©—è­‰é®ç½©ç›®éŒ„ï¼Œæ”¯æ´å¤šç¨®æ ¼å¼"""

            # æŸ¥æ‰¾åœ–åƒçµæœç›®éŒ„
            image_dirs = [d for d in segmentation_dir.iterdir()
                         if d.is_dir() and d.name.startswith('image')]

            if len(image_dirs) < 2:
                print(f"âŒ åœ–åƒç›®éŒ„æ•¸é‡ä¸è¶³: {len(image_dirs)} < 2")
                return None, None, None

            image_dirs.sort()  # ç¢ºä¿é †åºä¸€è‡´

            # æŒ‰å„ªå…ˆé †åºå°‹æ‰¾é®ç½©ç›®éŒ„é¡å‹
            mask_dir_types = [
                'single_pass_masks',  # å„ªå…ˆï¼šå–®æ¬¡åˆ†å‰²ç›®éŒ„
                'all_masks'           # å‚™ç”¨ï¼šå…©æ¬¡åˆ†å‰²ç›®éŒ„
            ]

            for mask_dir_type in mask_dir_types:
                masks_1_candidate = image_dirs[0] / mask_dir_type
                masks_2_candidate = image_dirs[1] / mask_dir_type

                print(f"ğŸ” æª¢æŸ¥ {mask_dir_type} ç›®éŒ„:")
                print(f"  - ç›®éŒ„1: {masks_1_candidate} (å­˜åœ¨: {masks_1_candidate.exists()})")
                print(f"  - ç›®éŒ„2: {masks_2_candidate} (å­˜åœ¨: {masks_2_candidate.exists()})")

                if masks_1_candidate.exists() and masks_2_candidate.exists():
                    # é©—è­‰æ˜¯å¦æœ‰è¶³å¤ çš„é®ç½©æª”æ¡ˆ
                    mask_files_1 = list(masks_1_candidate.glob("mask_*.png"))
                    mask_files_2 = list(masks_2_candidate.glob("mask_*.png"))

                    print(f"  - ç›®éŒ„1é®ç½©æª”æ¡ˆ: {len(mask_files_1)} å€‹")
                    print(f"  - ç›®éŒ„2é®ç½©æª”æ¡ˆ: {len(mask_files_2)} å€‹")

                    if len(mask_files_1) >= 1 and len(mask_files_2) >= 1:
                        print(f"âœ… æ‰¾åˆ°æœ‰æ•ˆé®ç½©ç›®éŒ„: {mask_dir_type}")
                        return str(masks_1_candidate), str(masks_2_candidate), mask_dir_type
                    else:
                        print(f"âš ï¸ {mask_dir_type} ç›®éŒ„å­˜åœ¨ä½†é®ç½©æª”æ¡ˆä¸è¶³")
                else:
                    print(f"âš ï¸ {mask_dir_type} ç›®éŒ„ä¸å­˜åœ¨æˆ–ä¸å®Œæ•´")

            print(f"âŒ æ‰¾ä¸åˆ°ä»»ä½•æœ‰æ•ˆçš„é®ç½©ç›®éŒ„")
            return None, None, None

        # æŸ¥æ‰¾åˆ†å‰²çµæœ
        segmentation_dir = Path(run_dir) / 'segmentation'

        if not segmentation_dir.exists():
            print(f"âŒ åˆ†å‰²ç›®éŒ„ä¸å­˜åœ¨: {segmentation_dir}")
            return create_error_response('åˆ†å‰²ç›®éŒ„ä¸å­˜åœ¨', 400)

        print(f"ğŸ“ åˆ†å‰²ç›®éŒ„å­˜åœ¨: {segmentation_dir}")

        # ä½¿ç”¨çµ±ä¸€çš„ç›®éŒ„æŸ¥æ‰¾é‚è¼¯
        masks_1_path, masks_2_path, found_mask_type = find_mask_directories(segmentation_dir)

        if masks_1_path is None or masks_2_path is None:
            # ğŸ”§ å‚™ç”¨æ–¹æ¡ˆï¼šæŸ¥æ‰¾ pickle æª”æ¡ˆ
            print("âš ï¸ é®ç½©ç›®éŒ„æŸ¥æ‰¾å¤±æ•—ï¼Œå˜—è©¦å°‹æ‰¾ pickle æª”æ¡ˆ...")

            pickle_files = []
            for root, dirs, files in os.walk(segmentation_dir):
                for file in files:
                    if (file.endswith('_single_pass_complete.pkl') or
                        file.endswith('_two_pass_complete.pkl') or
                        file.endswith('_masks_complete.pkl')):
                        pickle_files.append(os.path.join(root, file))

            if len(pickle_files) >= 2:
                pickle_files.sort()
                masks_1_path = pickle_files[0]
                masks_2_path = pickle_files[1]
                found_mask_type = 'pickle_files'
                print(f"âœ… ä½¿ç”¨ pickle æª”æ¡ˆ:")
                print(f"  - æª”æ¡ˆ1: {Path(masks_1_path).name}")
                print(f"  - æª”æ¡ˆ2: {Path(masks_2_path).name}")
            else:
                print(f"âŒ æ‰¾ä¸åˆ°è¶³å¤ çš„ pickle æª”æ¡ˆ: {len(pickle_files)} å€‹")
                return create_error_response('ç„¡æ³•æ‰¾åˆ°è¶³å¤ çš„é®ç½©æª”æ¡ˆé€²è¡ŒåŒ¹é…', 400)

        # æœ€çµ‚è·¯å¾‘é©—è­‰
        path1_exists = Path(masks_1_path).exists()
        path2_exists = Path(masks_2_path).exists()

        print(f"ğŸ“ æœ€çµ‚è·¯å¾‘é©—è­‰:")
        print(f"  - è·¯å¾‘1å­˜åœ¨: {path1_exists} ({masks_1_path})")
        print(f"  - è·¯å¾‘2å­˜åœ¨: {path2_exists} ({masks_2_path})")

        if not path1_exists or not path2_exists:
            return create_error_response('é®ç½©æª”æ¡ˆè·¯å¾‘ä¸å­˜åœ¨', 400)

        # è¼‰å…¥é®ç½©è³‡æ–™
        print(f"ğŸ”„ è¼‰å…¥é®ç½©è³‡æ–™ (é¡å‹: {found_mask_type})...")
        masks_data_1, masks_data_2 = load_masks_from_pickle(masks_1_path, masks_2_path)

        if masks_data_1 is None or masks_data_2 is None:
            return create_error_response('è¼‰å…¥é®ç½©è³‡æ–™å¤±æ•—', 500)

        print(f"âœ… é®ç½©è³‡æ–™è¼‰å…¥æˆåŠŸ:")
        print(f"  - é®ç½©1æ•¸é‡: {len(masks_data_1.get('masks', []))}")
        print(f"  - é®ç½©2æ•¸é‡: {len(masks_data_2.get('masks', []))}")

        # ç²å–åœ–åƒè·¯å¾‘
        image1_path = session.get('ref_image', {}).get('path')
        image2_path = session.get('input_image', {}).get('path')

        print(f"ğŸ“¸ åœ–åƒè·¯å¾‘:")
        print(f"  - åœ–åƒ1: {image1_path}")
        print(f"  - åœ–åƒ2: {image2_path}")

        # åŸ·è¡ŒåŒ¹é…
        print("ğŸš€ é–‹å§‹åŸ·è¡Œé®ç½©åŒ¹é…...")

        result = match_masks_with_images_api(
            masks_data_1, masks_data_2,
            image1_path, image2_path,
            str(output_dir),
            data.get('iou_threshold', 0.2),
            data.get('distance_threshold', 50),
            data.get('similarity_threshold', 0.25)
        )

        # æ›´æ–°é‹è¡Œç‹€æ…‹
        if result.get('status') == 'success':
            stats = result.get('data', {}).get('statistics', {})
            files_info = [
                f"matched: {stats.get('matched_objects', 0)}",
                f"disappeared: {stats.get('disappeared_objects', 0)}",
                f"new: {stats.get('new_objects', 0)}",
                f"mask_type: {found_mask_type}"
            ]

            run_manager.update_run_status(run_number, 'matching', 'completed', files_info)
            print(f"âœ… é‹è¡Œç‹€æ…‹å·²æ›´æ–° - åŒ¹é…å®Œæˆ")

        print(f"ğŸ“Š é®ç½©åŒ¹é…çµæœ: {result.get('status')}")
        print("=" * 60)

        serializable_result = convert_numpy_types(result)
        return jsonify(serializable_result)

    except Exception as e:
        print("=" * 60)
        print(f"ğŸ’¥ é®ç½©åŒ¹é…ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        traceback.print_exc()
        print("=" * 60)
        return create_error_response(f'é®ç½©åŒ¹é…å¤±æ•—: {str(e)}', 500)


@app.route('/api/detect_change', methods=['POST'])
def detect_change():
    try:
        print("ğŸ” è®ŠåŒ–æª¢æ¸¬ API è¢«èª¿ç”¨")
        print(f"â° æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        data = request.get_json()
        session_id = data.get('session_id')

        # ğŸ”§ ä¿®æ­£ï¼šä½¿ç”¨æ­£ç¢ºçš„ session_data æª¢æŸ¥
        if session_id not in session_data:
            return jsonify({
                'success': False,
                'error': 'æ²’æœ‰æ´»å‹•çš„é‹è¡Œéšæ®µ',
                'details': 'è«‹å…ˆåŸ·è¡Œä¸Šå‚³å’Œåˆ†å‰²æ­¥é©Ÿ'
            }), 400

        session = session_data[session_id]
        run_number = session.get('run_number')
        run_dir = session.get('run_directory')

        print(f"ğŸ”¢ é‹è¡Œç·¨è™Ÿ: {run_number}")

        # è¨­å®šè·¯å¾‘
        run_dir_path = Path(run_dir)
        upload_dir = run_dir_path / 'upload'
        matching_dir = run_dir_path / 'matching'
        detection_dir = run_dir_path / 'detection'

        print(f"ğŸ“ æª¢æ¸¬è¼¸å‡ºç›®éŒ„: {detection_dir}")

        # ç¢ºä¿detectionç›®éŒ„å­˜åœ¨
        detection_dir.mkdir(parents=True, exist_ok=True)

        # ğŸ”§ ä¿®æ­£ï¼šå„ªå…ˆä½¿ç”¨å¤©ç©ºå»é™¤è™•ç†å¾Œçš„åœ–ç‰‡ï¼Œå›é€€åˆ°åŸå§‹åœ–ç‰‡
        image1_path = session.get('sky_removed_image1', {}).get('path') or session['ref_image']['path']
        image2_path = session.get('sky_removed_image2', {}).get('path') or session['input_image']['path']

        print(f"ğŸ“ åœ–ç‰‡1: {Path(image1_path).name} ({'å¤©ç©ºè™•ç†å¾Œ' if 'sky_removed_image1' in session else 'åŸå§‹åœ–ç‰‡'})")
        print(f"ğŸ“ åœ–ç‰‡2: {Path(image2_path).name} ({'å¤©ç©ºè™•ç†å¾Œ' if 'sky_removed_image2' in session else 'åŸå§‹åœ–ç‰‡'})")

        print("ğŸš€ é–‹å§‹åŸ·è¡Œè®ŠåŒ–æª¢æ¸¬...")

        # å‘¼å«æ–°çš„ç´‹ç†æª¢æ¸¬å‡½æ•¸
        result = detect_changes_with_texture_analysis(
            image1_path=image1_path,
            image2_path=image2_path,
            matching_results_path=str(matching_dir),
            detection_output_path=str(detection_dir)
        )

        if result['success']:
            # æ›´æ–°é‹è¡Œç‹€æ…‹
            run_manager.update_run_status(run_number, 'detection', 'completed')

            print("âœ… é‹è¡Œç‹€æ…‹å·²æ›´æ–° - æª¢æ¸¬å®Œæˆ")
            print(f"ğŸ“Š è®ŠåŒ–æª¢æ¸¬çµæœ: success")

            # ç”Ÿæˆç‰©ä»¶æª¢è¦–è³‡æ–™
            objects_data = generate_objects_data(result, detection_dir)

            # ğŸ“ ä¿å­˜å®Œæ•´çµæœåˆ° result.json ä¾›æ­·å²å›é¡§ä½¿ç”¨
            complete_result = {
                'run_id': f'run_{run_number:03d}',
                'timestamp': datetime.now().isoformat(),
                'generated_images': result['generated_images'],
                'separated_images': result['generated_images'],
                'output_directory': str(result['output_path']),
                'mask_folders': result['mask_folders'],
                'statistics': result['statistics'],
                'report_path': str(result['report_path']),
                'disappeared_objects': objects_data['disappeared'],
                'appeared_objects': objects_data['appeared'],
                'same_objects': [],  # å¦‚æœæœ‰ç›¸åŒç‰©ä»¶è³‡æ–™å¯ä»¥åœ¨é€™è£¡æ·»åŠ 
                'visualization_images': [
                    {
                        'title': 'è®ŠåŒ–æª¢æ¸¬çµæœ',
                        'description': 'é¡¯ç¤ºåœ–ç‰‡é–“çš„è®ŠåŒ–å€åŸŸ',
                        'path': f'/api/files/run_{run_number:03d}/detection/detection_result.jpg'
                    }
                ] if 'detection_result.jpg' in [Path(img).name for img in result.get('generated_images', [])] else []
            }

            result_file = run_dir_path / 'result.json'
            with open(result_file, 'w', encoding='utf-8') as f:
                json.dump(complete_result, f, indent=2, ensure_ascii=False)
            print(f"ğŸ’¾ çµæœå·²ä¿å­˜åˆ°: {result_file}")

            return jsonify({
                'success': True,
                'message': 'è®ŠåŒ–æª¢æ¸¬å®Œæˆ',
                'data': {
                    'generated_images': result['generated_images'],
                    'separated_images': result['generated_images'],  # ğŸ”§ å‘ä¸‹ç›¸å®¹
                    'output_directory': result['output_path'],
                    'mask_folders': result['mask_folders'],
                    'statistics': result['statistics'],
                    'report_path': result['report_path'],
                    'analysis_results': {
                        'disappeared_objects': objects_data['disappeared'],
                        'appeared_objects': objects_data['appeared']
                    }
                }
            })
        else:
            return jsonify({
                'success': False,
                'error': result.get('error', 'æª¢æ¸¬éç¨‹ç™¼ç”ŸæœªçŸ¥éŒ¯èª¤'),
                'details': result
            }), 500

    except Exception as e:
        print("=" * 60)
        print(f"ğŸ’¥ è®ŠåŒ–æª¢æ¸¬ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        import traceback
        traceback.print_exc()
        print("=" * 60)

        return jsonify({
            'success': False,
            'error': f'è®ŠåŒ–æª¢æ¸¬å¤±æ•—: {str(e)}',
            'details': traceback.format_exc()
        }), 500

@app.route('/api/process_pipeline', methods=['POST'])
def process_pipeline():
    """å®Œæ•´è™•ç†æµç¨‹ç«¯é» - æ•´åˆé‹è¡Œç®¡ç†"""
    try:
        print("=" * 60)
        print("ğŸ”„ å®Œæ•´è™•ç†æµç¨‹ API è¢«èª¿ç”¨")
        print(f"â° æ™‚é–“: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")

        data = request.get_json()
        session_id = data.get('session_id')

        if not session_id or session_id not in session_data:
            return create_error_response('ç„¡æ•ˆçš„å·¥ä½œéšæ®µID', 400)

        session = session_data[session_id]
        run_number = session.get('run_number')
        run_dir = session.get('run_directory')

        print(f"ğŸ”¢ é‹è¡Œç·¨è™Ÿ: {run_number}")
        print(f"ğŸ“ é‹è¡Œç›®éŒ„: {run_dir}")

        results = {'pipeline_steps': []}

        try:
            # ä½¿ç”¨é‹è¡Œç®¡ç†çš„å„å€‹æ­¥é©Ÿ
            # ç”±æ–¼æ¯å€‹æ­¥é©Ÿéƒ½å·²ç¶“æ•´åˆäº†é‹è¡Œç®¡ç†ï¼Œé€™è£¡ä¸»è¦æ˜¯å”èª¿æµç¨‹

            # æ­¥é©Ÿ 1: åœ–åƒå°é½Š
            if 'ref_image' in session and 'input_image' in session:
                # æ¨¡æ“¬èª¿ç”¨å°é½Š APIï¼ˆå¯¦éš›ä¸Šæœƒé€šé HTTP èª¿ç”¨ï¼‰
                pass

            # å…¶ä»–æ­¥é©Ÿé¡ä¼¼...

            results.update({
                'status': 'success',
                'message': 'å®Œæ•´æµç¨‹åŸ·è¡Œå®Œæˆ',
                'run_number': run_number,
                'run_directory': run_dir,
                'total_steps': len(results['pipeline_steps'])
            })

            serializable_results = convert_numpy_types(results)
            return jsonify(serializable_results)

        except Exception as pipeline_error:
            results.update({
                'status': 'error',
                'message': 'æµç¨‹åŸ·è¡Œå¤±æ•—',
                'error': str(pipeline_error),
                'run_number': run_number,
                'completed_steps': len(results['pipeline_steps'])
            })

            serializable_results = convert_numpy_types(results)
            return jsonify(serializable_results), 500

    except Exception as e:
        print("=" * 60)
        print(f"ğŸ’¥ å®Œæ•´æµç¨‹ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {str(e)}")
        traceback.print_exc()
        print("=" * 60)
        return create_error_response(f'æµç¨‹åŸ·è¡Œå¤±æ•—: {str(e)}', 500)

# ğŸ”§ ä¿®å¾©ï¼šæª”æ¡ˆæœå‹™è·¯ç”±
@app.route('/api/files/<path:filename>')
def serve_file(filename):
    """æä¾›æª”æ¡ˆæœå‹™ - æ”¯æ´é‹è¡Œç›®éŒ„çµæ§‹"""
    try:
        print(f"ğŸ“ æª”æ¡ˆæœå‹™è«‹æ±‚: {filename}")

        # å®‰å…¨æª¢æŸ¥
        if '..' in filename or filename.startswith('/'):
            return create_error_response('ç„¡æ•ˆçš„æª”æ¡ˆè·¯å¾‘', 400)

        project_root = Path(__file__).parent.parent.absolute()

        # ğŸ”§ è™•ç†é‹è¡Œç‰¹å®šæª”æ¡ˆè·¯å¾‘ (å¦‚: run_008/upload/image1.jpg)
        if '/' in filename:
            parts = filename.split('/')
            if len(parts) >= 3 and parts[0].startswith('run_'):
                run_id = parts[0]
                subdir = parts[1]
                file_name = '/'.join(parts[2:])  # æ”¯æ´å¤šå±¤åµŒå¥—

                target_path = project_root / 'results' / 'runs' / run_id / subdir / file_name
                print(f"ğŸ” é‹è¡Œç‰¹å®šæª”æ¡ˆ: {target_path}")

                if target_path.exists() and target_path.is_file():
                    print(f"âœ… æ‰¾åˆ°é‹è¡Œæª”æ¡ˆ: {target_path}")

                    # è¨­å®š MIME é¡å‹
                    mimetype = None
                    if file_name.lower().endswith(('.jpg', '.jpeg')):
                        mimetype = 'image/jpeg'
                    elif file_name.lower().endswith('.png'):
                        mimetype = 'image/png'

                    return send_file(str(target_path), mimetype=mimetype)
        if filename.startswith('results/'):
            full_path = project_root / filename
            print(f"ğŸ” å˜—è©¦è¼‰å…¥æª”æ¡ˆ: {full_path}")

            if full_path.exists() and full_path.is_file():
                print(f"âœ… æ‰¾åˆ°æª”æ¡ˆ: {full_path}")

                # è¨­å®š MIME é¡å‹
                mimetype = None
                if filename.lower().endswith(('.jpg', '.jpeg')):
                    mimetype = 'image/jpeg'
                elif filename.lower().endswith('.png'):
                    mimetype = 'image/png'

                return send_file(str(full_path), mimetype=mimetype)

        # ğŸ”§ å‚™ç”¨ï¼šæœå°‹é‹è¡Œç›®éŒ„ï¼ˆé©ç”¨æ–¼ç›¸å°è·¯å¾‘ï¼‰
        runs_dir = project_root / 'results' / 'runs'
        if runs_dir.exists():
            # æŒ‰æ™‚é–“æ’åºï¼Œæœå°‹æœ€æ–°çš„é‹è¡Œç›®éŒ„
            run_dirs = sorted([d for d in runs_dir.iterdir() if d.is_dir() and d.name.startswith('run_')],
                            key=lambda x: x.stat().st_ctime, reverse=True)

            for run_dir in run_dirs[:5]:  # æœå°‹æœ€æ–°çš„5å€‹é‹è¡Œ
                for subdir in ['upload', 'alignment', 'segmentation', 'matching', 'detection', 'video_processing']:
                    search_path = run_dir / subdir
                    if search_path.exists():
                        target_file = search_path / filename
                        if target_file.exists() and target_file.is_file():
                            print(f"âœ… åœ¨é‹è¡Œç›®éŒ„ä¸­æ‰¾åˆ°æª”æ¡ˆ: {target_file}")

                            # è¨­å®š MIME é¡å‹
                            mimetype = None
                            if filename.lower().endswith(('.jpg', '.jpeg')):
                                mimetype = 'image/jpeg'
                            elif filename.lower().endswith('.png'):
                                mimetype = 'image/png'

                            return send_file(str(target_file), mimetype=mimetype)

                        # ğŸ¥ æ–°å¢ï¼šæª¢æŸ¥video_processing/frameså­ç›®éŒ„
                        if subdir == 'video_processing':
                            frames_path = search_path / 'frames'
                            if frames_path.exists():
                                target_file = frames_path / filename
                                if target_file.exists() and target_file.is_file():
                                    print(f"âœ… åœ¨å½±æ ¼ç›®éŒ„ä¸­æ‰¾åˆ°æª”æ¡ˆ: {target_file}")

                                    # è¨­å®š MIME é¡å‹
                                    mimetype = None
                                    if filename.lower().endswith(('.jpg', '.jpeg')):
                                        mimetype = 'image/jpeg'
                                    elif filename.lower().endswith('.png'):
                                        mimetype = 'image/png'

                                    return send_file(str(target_file), mimetype=mimetype)

        # å‚™ç”¨ï¼šæœå°‹åŸæœ‰çš„ temp ç›®éŒ„çµæ§‹
        results_dir = project_root / 'results'
        if results_dir.exists():
            temp_dirs = sorted([d for d in results_dir.iterdir()
                              if d.is_dir() and d.name.startswith('temp_')],
                             key=lambda x: x.stat().st_ctime, reverse=True)

            for temp_dir in temp_dirs[:5]:
                target_file = temp_dir / filename
                if target_file.exists() and target_file.is_file():
                    print(f"âœ… åœ¨è‡¨æ™‚ç›®éŒ„ä¸­æ‰¾åˆ°æª”æ¡ˆ: {target_file}")
                    return send_file(str(target_file), mimetype='image/jpeg')

        return create_error_response('æª”æ¡ˆä¸å­˜åœ¨æˆ–ç„¡æ³•å­˜å–', 404)

    except Exception as e:
        print(f"ğŸ’¥ æª”æ¡ˆæœå‹™ç™¼ç”Ÿåš´é‡éŒ¯èª¤: {str(e)}")
        return create_error_response(f'æª”æ¡ˆæœå‹™å¤±æ•—: {str(e)}', 500)

@app.route('/api/cleanup', methods=['POST'])
def cleanup_session():
    """æ¸…ç†å·¥ä½œéšæ®µ"""
    try:
        data = request.get_json() or {}
        session_id = data.get('session_id')

        if session_id and session_id in session_data:
            session = session_data[session_id]
            run_number = session.get('run_number')

            # æ›´æ–°é‹è¡Œç‹€æ…‹ç‚ºå·²æ¸…ç†
            if run_number:
                run_manager.update_run_status(run_number, 'cleanup', 'completed')

            # æ¸…ç†æª”æ¡ˆ
            for key in session:
                if isinstance(session[key], dict) and 'path' in session[key]:
                    cleanup_temp_files([session[key]['path']])
                elif isinstance(session[key], list):
                    paths = [item['path'] for item in session[key] if 'path' in item]
                    cleanup_temp_files(paths)

            # ç§»é™¤å·¥ä½œéšæ®µ
            del session_data[session_id]

        return create_success_response({'message': 'å·¥ä½œéšæ®µæ¸…ç†å®Œæˆ'})

    except Exception as e:
        return create_error_response(f'æ¸…ç†å¤±æ•—: {str(e)}', 500)

@app.errorhandler(413)
def too_large(e):
    return create_error_response('æª”æ¡ˆå¤ªå¤§ï¼Œè«‹ä¸Šå‚³å°æ–¼100MBçš„æª”æ¡ˆ', 413)

@app.errorhandler(404)
def not_found(e):
    return create_error_response('APIç«¯é»ä¸å­˜åœ¨', 404)

@app.errorhandler(500)
def internal_error(e):
    return create_error_response('ä¼ºæœå™¨å…§éƒ¨éŒ¯èª¤', 500)

def validate_alignment_parameters_enhanced(data, session_data):
    """å¢å¼·ç‰ˆåƒæ•¸é©—è­‰ï¼Œå„ªå…ˆæª¢æŸ¥ session_id"""
    session_id = data.get('session_id')

    if session_id:
        if session_id not in session_data:
            return False, f"ç„¡æ•ˆçš„å·¥ä½œéšæ®µID: {session_id}"

        session = session_data[session_id]

        if 'ref_image' not in session:
            return False, "å·¥ä½œéšæ®µè³‡æ–™ä¸å®Œæ•´ï¼šç¼ºå°‘åƒè€ƒåœ–åƒ"
        if 'input_image' not in session:
            return False, "å·¥ä½œéšæ®µè³‡æ–™ä¸å®Œæ•´ï¼šç¼ºå°‘è¼¸å…¥åœ–åƒ"

        ref_path = session['ref_image'].get('path')
        input_path = session['input_image'].get('path')

        if not ref_path or not input_path:
            return False, "å·¥ä½œéšæ®µè³‡æ–™ä¸å®Œæ•´ï¼šåœ–åƒè·¯å¾‘ç‚ºç©º"

        return True, None

    if not data.get('ref_path') or not data.get('input_path'):
        return False, "ç¼ºå°‘å¿…è¦åƒæ•¸: éœ€è¦ session_id æˆ– ref_path/input_path"

    return True, None

if __name__ == '__main__':
    print("ğŸš€ ç…§ç‰‡è®ŠåŒ–æª¢æ¸¬ç³»çµ±å¾Œç«¯å•Ÿå‹• (æ•´åˆé‹è¡Œç®¡ç†)")
    print("ğŸ“ API åŸºç¤ URL: http://127.0.0.1:5000/api")
    print("ğŸ”§ æ”¯æ´åŠŸèƒ½:")
    print("  - é–‹å§‹æ–°é‹è¡Œ: /api/start_new_run")
    print("  - åˆ—å‡ºé‹è¡Œ: /api/runs")
    print("  - é‹è¡Œè©³æƒ…: /api/run/<run_number>")
    print("  - æª”æ¡ˆä¸Šå‚³: /api/upload")
    print("  - åœ–åƒå°é½Š: /api/align")
    print("  - SAM2 åˆ†å‰²: /api/segment")
    print("  - é®ç½©åŒ¹é…: /api/match_masks")
    print("  - è®ŠåŒ–æª¢æ¸¬: /api/detect_change")
    print("  - å®Œæ•´æµç¨‹: /api/process_pipeline")
    print("  - å½±ç‰‡è™•ç†: /api/extract_frames")
    print("  - æª”æ¡ˆæœå‹™: /api/files/<filename>")
    print("ğŸ“Š ç³»çµ±å¥åº·: /api/health")
    print("ğŸ—‚ï¸ é‹è¡Œç®¡ç†å·²å•Ÿç”¨ - ç³»çµ±åŒ–ç®¡ç†æ‰€æœ‰è™•ç†çµæœ")
    print("ğŸ“ é‹è¡Œç›®éŒ„çµæ§‹: results/runs/run_XXX/[upload|alignment|segmentation|matching|detection]")

    app.run(debug=True, host='0.0.0.0', port=5000)
