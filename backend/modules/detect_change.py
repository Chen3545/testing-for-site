import cv2
import numpy as np
import os
from pathlib import Path
import json
import torch
import torch.nn.functional as F
from PIL import Image
import torchvision.transforms as transforms
import warnings
warnings.filterwarnings("ignore", category=UserWarning, module="matplotlib")

# å°å…¥ ViT ç›¸é—œæ¨¡çµ„
try:
    from transformers import ViTModel, ViTConfig
    VIT_AVAILABLE = True
except ImportError:
    print("âš ï¸ è­¦å‘Šï¼šç„¡æ³•å°å…¥ transformersï¼Œå°‡ä½¿ç”¨å‚™ç”¨ç‰¹å¾µæå–æ–¹æ³•")
    VIT_AVAILABLE = False

class ViTTextureExtractor:
    """åŸºæ–¼ Vision Transformer çš„ç´‹ç†ç‰¹å¾µæå–å™¨"""

    def __init__(self, device='auto'):
        """åˆå§‹åŒ– ViT ç´‹ç†ç‰¹å¾µæå–å™¨"""
        self.device = self._setup_device(device)
        self.model = None
        self.transform = None
        self._load_model()
        print(f"ğŸ¤– ViT ç´‹ç†æå–å™¨å·²åˆå§‹åŒ– (è¨­å‚™: {self.device})")

    def _setup_device(self, device):
        """è¨­å®šè¨ˆç®—è¨­å‚™"""
        if device == 'auto':
            if torch.cuda.is_available():
                return torch.device('cuda')
            else:
                return torch.device('cpu')
        else:
            return torch.device(device)

    def _load_model(self):
        """è¼‰å…¥ ViT é è¨“ç·´æ¨¡å‹"""
        try:
            if VIT_AVAILABLE:
                # ä½¿ç”¨ ViT-Base æ¨¡å‹
                model_name = 'google/vit-base-patch16-224'
                self.model = ViTModel.from_pretrained(model_name)
                self.model.to(self.device)
                self.model.eval()

                # è¨­å®šåœ–åƒé è™•ç†
                self.transform = transforms.Compose([
                    transforms.Resize((224, 224)),
                    transforms.ToTensor(),
                    transforms.Normalize(mean=[0.485, 0.456, 0.406],
                                       std=[0.229, 0.224, 0.225])
                ])
                print("âœ… ViT æ¨¡å‹è¼‰å…¥æˆåŠŸ")
            else:
                # å‚™ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨å‚³çµ± CNN ç‰¹å¾µ
                self._load_fallback_model()
        except Exception as e:
            print(f"âš ï¸ ViT æ¨¡å‹è¼‰å…¥å¤±æ•—ï¼Œä½¿ç”¨å‚™ç”¨æ–¹æ¡ˆ: {e}")
            self._load_fallback_model()

    def _load_fallback_model(self):
        """å‚™ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨å‚³çµ±ç‰¹å¾µæå–"""
        print("ğŸ”§ ä½¿ç”¨å‚™ç”¨ç‰¹å¾µæå–æ–¹æ³•")
        self.model = None
        self.transform = transforms.Compose([
            transforms.Resize((224, 224)),
            transforms.ToTensor()
        ])

    def extract_region_features(self, image, mask):
        """æå–é®ç½©å€åŸŸçš„ç´‹ç†ç‰¹å¾µ"""
        try:
            # æå–é®ç½©å€åŸŸ
            masked_region = self._extract_masked_region(image, mask)
            if masked_region is None:
                return np.zeros(768)  # ViT-Base çš„ç‰¹å¾µç¶­åº¦

            # è½‰æ›ç‚º PIL åœ–åƒ
            if len(masked_region.shape) == 3:
                masked_region_rgb = cv2.cvtColor(masked_region, cv2.COLOR_BGR2RGB)
            else:
                masked_region_rgb = cv2.cvtColor(masked_region, cv2.COLOR_GRAY2RGB)

            pil_image = Image.fromarray(masked_region_rgb)

            # é è™•ç†
            input_tensor = self.transform(pil_image).unsqueeze(0)
            input_tensor = input_tensor.to(self.device)

            # ç‰¹å¾µæå–
            with torch.no_grad():
                if self.model is not None and VIT_AVAILABLE:
                    # ä½¿ç”¨ ViT æå–ç‰¹å¾µ
                    outputs = self.model(input_tensor)
                    features = outputs.last_hidden_state.mean(dim=1).squeeze()  # å…¨å±€å¹³å‡æ± åŒ–
                    features = features.cpu().numpy()
                else:
                    # å‚™ç”¨ï¼šä½¿ç”¨å‚³çµ±æ–¹æ³•
                    features = self._extract_traditional_features(masked_region)

            return features

        except Exception as e:
            print(f"âš ï¸ ç‰¹å¾µæå–å¤±æ•—: {e}")
            return np.zeros(768)

    def _extract_masked_region(self, image, mask):
        """æå–é®ç½©å€åŸŸä¸¦ç”Ÿæˆæœ‰æ•ˆçš„åœ–åƒå¡Š"""
        # æ‰¾åˆ°é®ç½©é‚Šç•Œ
        y_indices, x_indices = np.where(mask > 0)
        if len(y_indices) == 0:
            return None

        # è¨ˆç®—é‚Šç•Œæ¡†
        padding = 20
        y_min = max(0, y_indices.min() - padding)
        y_max = min(image.shape[0], y_indices.max() + padding)
        x_min = max(0, x_indices.min() - padding)
        x_max = min(image.shape[1], x_indices.max() + padding)

        # ç¢ºä¿æœ€å°å°ºå¯¸
        min_size = 32
        if (y_max - y_min) < min_size or (x_max - x_min) < min_size:
            # æ“´å±•åˆ°æœ€å°å°ºå¯¸
            y_center = (y_min + y_max) // 2
            x_center = (x_min + x_max) // 2
            y_min = max(0, y_center - min_size // 2)
            y_max = min(image.shape[0], y_center + min_size // 2)
            x_min = max(0, x_center - min_size // 2)
            x_max = min(image.shape[1], x_center + min_size // 2)

        # è£åˆ‡å€åŸŸ
        region = image[y_min:y_max, x_min:x_max]
        return region

    def _extract_traditional_features(self, region):
        """å‚™ç”¨ï¼šå‚³çµ±ç´‹ç†ç‰¹å¾µæå–"""
        try:
            # è½‰æ›ç‚ºç°éš
            if len(region.shape) == 3:
                gray = cv2.cvtColor(region, cv2.COLOR_BGR2GRAY)
            else:
                gray = region

            # èª¿æ•´å¤§å°
            gray = cv2.resize(gray, (64, 64))

            # è¨ˆç®—å¤šç¨®ç´‹ç†ç‰¹å¾µ
            features = []

            # 1. LBP (Local Binary Pattern)
            lbp = self._calculate_lbp(gray)
            features.extend(lbp.flatten()[:256])  # é™åˆ¶é•·åº¦

            # 2. GLCM ç‰¹å¾µ
            glcm_features = self._calculate_glcm_features(gray)
            features.extend(glcm_features)

            # 3. Gabor æ¿¾æ³¢å™¨éŸ¿æ‡‰
            gabor_features = self._calculate_gabor_features(gray)
            features.extend(gabor_features)

            # å¡«å……åˆ° 768 ç¶­
            while len(features) < 768:
                features.append(0.0)

            return np.array(features[:768])

        except Exception as e:
            print(f"âš ï¸ å‚³çµ±ç‰¹å¾µæå–å¤±æ•—: {e}")
            return np.zeros(768)

    def _calculate_lbp(self, gray):
        """è¨ˆç®— Local Binary Pattern"""
        try:
            # ç°¡åŒ–çš„ LBP å¯¦ç¾
            rows, cols = gray.shape
            lbp = np.zeros_like(gray)

            for i in range(1, rows-1):
                for j in range(1, cols-1):
                    center = gray[i, j]
                    code = 0
                    # 8-neighborhood
                    neighbors = [
                        gray[i-1, j-1], gray[i-1, j], gray[i-1, j+1],
                        gray[i, j+1], gray[i+1, j+1], gray[i+1, j],
                        gray[i+1, j-1], gray[i, j-1]
                    ]

                    for k, neighbor in enumerate(neighbors):
                        if neighbor >= center:
                            code |= (1 << k)

                    lbp[i, j] = code

            return lbp
        except Exception:
            return np.zeros((8, 8))

    def _calculate_glcm_features(self, gray):
        """è¨ˆç®— GLCM ç‰¹å¾µ"""
        try:
            # ç°¡åŒ–çš„ GLCM ç‰¹å¾µ
            features = []

            # è¨ˆç®—åŸºæœ¬çµ±è¨ˆç‰¹å¾µ
            features.append(float(np.mean(gray)))
            features.append(float(np.std(gray)))
            features.append(float(np.var(gray)))

            # è¨ˆç®—æ¢¯åº¦ç‰¹å¾µ
            grad_x = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=3)
            grad_y = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=3)
            features.append(float(np.mean(np.abs(grad_x))))
            features.append(float(np.mean(np.abs(grad_y))))

            return features[:20]  # é™åˆ¶ç‰¹å¾µæ•¸é‡
        except Exception:
            return [0.0] * 20

    def _calculate_gabor_features(self, gray):
        """è¨ˆç®— Gabor æ¿¾æ³¢å™¨ç‰¹å¾µ"""
        try:
            features = []

            # å¤šå€‹æ–¹å‘çš„ Gabor æ¿¾æ³¢å™¨
            for theta in [0, 45, 90, 135]:
                kernel = cv2.getGaborKernel((21, 21), 5, np.radians(theta),
                                          2*np.pi*0.5, 0.5, 0, ktype=cv2.CV_32F)
                filtered = cv2.filter2D(gray, cv2.CV_8UC3, kernel)
                features.append(float(np.mean(filtered)))
                features.append(float(np.std(filtered)))

            return features[:16]  # é™åˆ¶ç‰¹å¾µæ•¸é‡
        except Exception:
            return [0.0] * 16

    def calculate_similarity(self, features1, features2):
        """è¨ˆç®—å…©å€‹ç‰¹å¾µå‘é‡çš„ç›¸ä¼¼åº¦"""
        try:
            # ç¢ºä¿ç‰¹å¾µå‘é‡æœ‰æ•ˆ
            if np.allclose(features1, 0) or np.allclose(features2, 0):
                return 0.0

            # æ­£è¦åŒ–ç‰¹å¾µå‘é‡
            features1_norm = features1 / (np.linalg.norm(features1) + 1e-8)
            features2_norm = features2 / (np.linalg.norm(features2) + 1e-8)

            # è¨ˆç®—é¤˜å¼¦ç›¸ä¼¼åº¦
            similarity = np.dot(features1_norm, features2_norm)

            # ç¢ºä¿åœ¨ [0, 1] ç¯„åœå…§
            similarity = max(0.0, min(1.0, (similarity + 1) / 2))

            return float(similarity)

        except Exception as e:
            print(f"âš ï¸ ç›¸ä¼¼åº¦è¨ˆç®—å¤±æ•—: {e}")
            return 0.0

class MaskReclassifier:
    """é®ç½©äºŒæ¬¡é‡æ–°åˆ†é¡å™¨ - æ•´åˆè¦–è¦ºå·®ç•°é©—è­‰"""

    def __init__(self, feature_extractor):
        """åˆå§‹åŒ–é‡æ–°åˆ†é¡å™¨"""
        self.feature_extractor = feature_extractor

        # ğŸ”§ ä¿®æ”¹ç‚ºæ›´åš´æ ¼çš„é–¾å€¼
        self.reclassification_params = {
            'similarity_threshold_for_same': 0.60,      # ğŸ”§ é™ä½é–¾å€¼
            'similarity_threshold_for_different': 0.50,  # ğŸ”§ é™ä½é–¾å€¼
            'brightness_tolerance': 0.15,               # å¢åŠ äº®åº¦å®¹å¿åº¦
            'visual_difference_threshold': 0.12,        # ğŸ†• è¦–è¦ºå·®ç•°é–¾å€¼
            'brightness_penalty_threshold': 0.15,       # ğŸ†• äº®åº¦å·®ç•°æ‡²ç½°é–¾å€¼
            'max_brightness_penalty': 0.8,              # ğŸ†• æœ€å¤§äº®åº¦æ‡²ç½°
        }

        print("ğŸ”„ é®ç½©äºŒæ¬¡é‡æ–°åˆ†é¡å™¨å·²åˆå§‹åŒ–ï¼ˆæ•´åˆè¦–è¦ºå·®ç•°é©—è­‰ï¼‰")

    def calculate_mask_similarity(self, img_old, img_new, mask):
        """ğŸ†• æ”¹é€²ç‰ˆï¼šæ•´åˆç´‹ç†ã€äº®åº¦å·®ç•°å’Œè¦–è¦ºå·®ç•°é©—è­‰"""
        try:
            # åŸæœ‰çš„ç´‹ç†ç‰¹å¾µç›¸ä¼¼åº¦
            old_features = self.feature_extractor.extract_region_features(img_old, mask)
            new_features = self.feature_extractor.extract_region_features(img_new, mask)
            texture_similarity = self.feature_extractor.calculate_similarity(old_features, new_features)

            # ğŸ†• äº®åº¦å·®ç•°æ‡²ç½°
            brightness_penalty = self._calculate_brightness_difference_penalty(img_old, img_new, mask)

            # ğŸ†• è¦–è¦ºå·®ç•°æª¢æ¸¬
            visual_difference_penalty = self._calculate_visual_difference_penalty(img_old, img_new, mask)

            # ğŸ†• é‚Šç·£ä¸€è‡´æ€§æª¢æ¸¬
            edge_consistency = self._calculate_edge_consistency(img_old, img_new, mask)

            # ğŸ†• ç¶œåˆè¨ˆç®—æœ€çµ‚ç›¸ä¼¼åº¦
            final_similarity = texture_similarity * (1.0 - brightness_penalty) * (1.0 - visual_difference_penalty) * edge_consistency

            # ç¢ºä¿åœ¨ [0, 1] ç¯„åœå…§
            final_similarity = max(0.0, min(1.0, final_similarity))

            print(f"    ğŸ“Š ç´‹ç†: {texture_similarity:.3f}")
            print(f"    ğŸ”† äº®åº¦æ‡²ç½°: {brightness_penalty:.3f}")
            print(f"    ğŸ‘ï¸ è¦–è¦ºå·®ç•°æ‡²ç½°: {visual_difference_penalty:.3f}")
            print(f"    ğŸ”² é‚Šç·£ä¸€è‡´æ€§: {edge_consistency:.3f}")
            print(f"    â¡ï¸ æœ€çµ‚ç›¸ä¼¼åº¦: {final_similarity:.3f}")

            return final_similarity

        except Exception as e:
            print(f"âš ï¸ è¨ˆç®—é®ç½©ç›¸ä¼¼åº¦å¤±æ•—: {e}")
            return texture_similarity if 'texture_similarity' in locals() else 0.0

    def _calculate_brightness_difference_penalty(self, img_old, img_new, mask):
        """è¨ˆç®—äº®åº¦å·®ç•°æ‡²ç½°å€¼"""
        try:
            # è½‰æ›ç‚ºç°éš
            old_gray = cv2.cvtColor(img_old, cv2.COLOR_BGR2GRAY) if len(img_old.shape) == 3 else img_old
            new_gray = cv2.cvtColor(img_new, cv2.COLOR_BGR2GRAY) if len(img_new.shape) == 3 else img_new

            # æå–é®ç½©å€åŸŸçš„äº®åº¦
            old_brightness = old_gray[mask > 0]
            new_brightness = new_gray[mask > 0]

            if len(old_brightness) == 0 or len(new_brightness) == 0:
                return 0.0

            # è¨ˆç®—å¹³å‡äº®åº¦å·®ç•°
            old_mean = np.mean(old_brightness)
            new_mean = np.mean(new_brightness)
            brightness_diff = abs(old_mean - new_mean) / 255.0

            brightness_threshold = self.reclassification_params['brightness_penalty_threshold']
            max_penalty = self.reclassification_params['max_brightness_penalty']

            if brightness_diff > brightness_threshold:
                # ç·šæ€§æ‡²ç½°ï¼šå·®ç•°è¶Šå¤§ï¼Œæ‡²ç½°è¶Šé‡
                penalty = min(max_penalty, (brightness_diff - brightness_threshold) * 2.0)
                return penalty

            return 0.0

        except Exception as e:
            print(f"âš ï¸ äº®åº¦å·®ç•°è¨ˆç®—å¤±æ•—: {e}")
            return 0.0

    def _calculate_visual_difference_penalty(self, img_old, img_new, mask):
        """ğŸ†• è¨ˆç®—è¦–è¦ºå·®ç•°æ‡²ç½°å€¼"""
        try:
            # æå–é®ç½©å€åŸŸ
            old_region = img_old.copy()
            new_region = img_new.copy()

            # åªä¿ç•™é®ç½©å€åŸŸï¼Œå…¶ä»–è¨­ç‚ºé»‘è‰²
            old_region[mask == 0] = 0
            new_region[mask == 0] = 0

            # è¨ˆç®—ç›´æ¥çš„åƒç´ å·®ç•°
            diff = cv2.absdiff(old_region, new_region)

            # åªçœ‹é®ç½©å€åŸŸçš„å·®ç•°
            mask_diff = diff[mask > 0]

            if len(mask_diff) == 0:
                return 0.0

            # è¨ˆç®—å¹³å‡å·®ç•°ï¼ˆæ­¸ä¸€åŒ–åˆ° 0-1ï¼‰
            mean_diff = np.mean(mask_diff) / 255.0

            visual_threshold = self.reclassification_params['visual_difference_threshold']

            if mean_diff > visual_threshold:
                # ç·šæ€§æ‡²ç½°ï¼šè¦–è¦ºå·®ç•°è¶Šå¤§ï¼Œæ‡²ç½°è¶Šé‡
                penalty = min(0.9, (mean_diff - visual_threshold) * 3.0)  # æœ€å¤§æ‡²ç½°90%
                return penalty

            return 0.0

        except Exception as e:
            print(f"âš ï¸ è¦–è¦ºå·®ç•°è¨ˆç®—å¤±æ•—: {e}")
            return 0.0

    def _calculate_edge_consistency(self, img_old, img_new, mask):
        """ğŸ†• è¨ˆç®—é‚Šç·£ä¸€è‡´æ€§åˆ†æ•¸"""
        try:
            # è½‰æ›ç‚ºç°éš
            old_gray = cv2.cvtColor(img_old, cv2.COLOR_BGR2GRAY) if len(img_old.shape) == 3 else img_old
            new_gray = cv2.cvtColor(img_new, cv2.COLOR_BGR2GRAY) if len(img_new.shape) == 3 else img_new

            # Cannyé‚Šç·£æª¢æ¸¬
            old_edges = cv2.Canny(old_gray, 50, 150)
            new_edges = cv2.Canny(new_gray, 50, 150)

            # åªæ¯”è¼ƒé®ç½©å€åŸŸå…§çš„é‚Šç·£
            old_edges_masked = old_edges[mask > 0]
            new_edges_masked = new_edges[mask > 0]

            if len(old_edges_masked) == 0:
                return 1.0  # å¦‚æœæ²’æœ‰é‚Šç·£ï¼Œèªç‚ºä¸€è‡´

            # è¨ˆç®—é‚Šç·£ç›¸ä¼¼åº¦ï¼ˆé‚Šç·£çµæ§‹æ‡‰è©²ä¿æŒä¸€è‡´ï¼‰
            edge_diff = np.mean(np.abs(old_edges_masked.astype(float) - new_edges_masked.astype(float)))
            edge_consistency = max(0.3, 1.0 - edge_diff / 255.0)  # æœ€ä½ä¿æŒ30%çš„æ¬Šé‡

            return edge_consistency

        except Exception as e:
            print(f"âš ï¸ é‚Šç·£ä¸€è‡´æ€§è¨ˆç®—å¤±æ•—: {e}")
            return 1.0

    def reclassify_masks(self, img_old, img_new, original_same_masks,
                        original_disappeared_masks, original_appeared_masks):
        """æ ¹æ“šå¤šé‡é©—è­‰é‡æ–°åˆ†é¡æ‰€æœ‰é®ç½©"""

        print(f"\nğŸ”„ é–‹å§‹åŸ·è¡Œé®ç½©äºŒæ¬¡é‡æ–°åˆ†é¡ï¼ˆè¦–è¦ºå·®ç•°é©—è­‰ç‰ˆï¼‰...")
        print(f"ğŸ“Š åŸå§‹åˆ†é¡çµ±è¨ˆ:")
        print(f"  ç›¸åŒé®ç½©: {len(original_same_masks)} å€‹")
        print(f"  æ¶ˆå¤±é®ç½©: {len(original_disappeared_masks)} å€‹")
        print(f"  æ–°å¢é®ç½©: {len(original_appeared_masks)} å€‹")

        # é‡æ–°åˆ†é¡å¾Œçš„çµæœå®¹å™¨
        reclassified_same_masks = {}
        reclassified_disappeared_masks = {}
        reclassified_appeared_masks = {}

        similarity_threshold_same = self.reclassification_params['similarity_threshold_for_same']
        similarity_threshold_different = self.reclassification_params['similarity_threshold_for_different']

        # çµ±è¨ˆè³‡è¨Š
        stats = {
            'appeared_to_same': 0,
            'disappeared_to_same': 0,
            'same_kept': 0,
            'appeared_kept': 0,
            'disappeared_kept': 0,
            'visual_diff_detected': 0,
            'brightness_penalty_applied': 0
        }

        # Step 1: é‡æ–°åˆ†é¡ã€Œæ–°å¢é®ç½©ã€
        print(f"\nğŸŸ¢ Step 1: é‡æ–°åˆ†é¡æ–°å¢é®ç½© ({len(original_appeared_masks)} å€‹)")
        for mask_name, mask in original_appeared_masks.items():
            try:
                mask_area = np.count_nonzero(mask)
                if mask_area == 0:
                    continue

                print(f"  ğŸ” æ–°å¢é®ç½©: {mask_name[:20]}...")

                # ğŸ†• ä½¿ç”¨æ”¹é€²çš„ç›¸ä¼¼åº¦è¨ˆç®—
                similarity = self.calculate_mask_similarity(img_old, img_new, mask)

                if similarity >= similarity_threshold_same:
                    # é‡æ–°åˆ†é¡ç‚ºç›¸åŒé®ç½©
                    reclassified_same_masks[mask_name] = mask
                    stats['appeared_to_same'] += 1
                    print(f"  ğŸ”„ æ–°å¢â†’ç›¸åŒ (ç›¸ä¼¼åº¦ {similarity:.3f} >= {similarity_threshold_same})")
                else:
                    # ä¿æŒç‚ºæ–°å¢é®ç½©
                    reclassified_appeared_masks[mask_name] = mask
                    stats['appeared_kept'] += 1
                    print(f"  âœ… ä¿æŒæ–°å¢ (ç›¸ä¼¼åº¦ {similarity:.3f} < {similarity_threshold_same})")

            except Exception as e:
                print(f"  âŒ è™•ç†æ–°å¢é®ç½© {mask_name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                reclassified_appeared_masks[mask_name] = mask
                continue

        # Step 2: é‡æ–°åˆ†é¡ã€Œæ¶ˆå¤±é®ç½©ã€
        print(f"\nğŸ”´ Step 2: é‡æ–°åˆ†é¡æ¶ˆå¤±é®ç½© ({len(original_disappeared_masks)} å€‹)")
        for mask_name, mask in original_disappeared_masks.items():
            try:
                mask_area = np.count_nonzero(mask)
                if mask_area == 0:
                    continue

                print(f"  ğŸ” æ¶ˆå¤±é®ç½©: {mask_name[:20]}...")

                # ğŸ†• ä½¿ç”¨æ”¹é€²çš„ç›¸ä¼¼åº¦è¨ˆç®—
                similarity = self.calculate_mask_similarity(img_old, img_new, mask)

                if similarity >= similarity_threshold_same:
                    # é‡æ–°åˆ†é¡ç‚ºç›¸åŒé®ç½©
                    reclassified_same_masks[mask_name] = mask
                    stats['disappeared_to_same'] += 1
                    print(f"  ğŸ”„ æ¶ˆå¤±â†’ç›¸åŒ (ç›¸ä¼¼åº¦ {similarity:.3f} >= {similarity_threshold_same})")
                else:
                    # ä¿æŒç‚ºæ¶ˆå¤±é®ç½©
                    reclassified_disappeared_masks[mask_name] = mask
                    stats['disappeared_kept'] += 1
                    print(f"  âœ… ä¿æŒæ¶ˆå¤± (ç›¸ä¼¼åº¦ {similarity:.3f} < {similarity_threshold_same})")

            except Exception as e:
                print(f"  âŒ è™•ç†æ¶ˆå¤±é®ç½© {mask_name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                reclassified_disappeared_masks[mask_name] = mask
                continue

        # Step 3: è™•ç†ã€Œç›¸åŒé®ç½©ã€ï¼ˆä¿æŒç›¸åŒï¼‰
        print(f"\nğŸ”µ Step 3: è™•ç†ç›¸åŒé®ç½© ({len(original_same_masks)} å€‹)")
        for mask_name, mask in original_same_masks.items():
            try:
                mask_area = np.count_nonzero(mask)
                if mask_area == 0:
                    continue

                # ä¿æŒç‚ºç›¸åŒé®ç½©
                reclassified_same_masks[mask_name] = mask
                stats['same_kept'] += 1
                print(f"  âœ… ä¿æŒç›¸åŒ: {mask_name[:20]}...")

            except Exception as e:
                print(f"  âŒ è™•ç†ç›¸åŒé®ç½© {mask_name} æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
                reclassified_same_masks[mask_name] = mask
                continue

        # çµ±è¨ˆçµæœ
        print(f"\nğŸ“Š é‡æ–°åˆ†é¡çµæœçµ±è¨ˆ:")
        print(f"  æ–°å¢â†’ç›¸åŒ: {stats['appeared_to_same']} å€‹")
        print(f"  æ¶ˆå¤±â†’ç›¸åŒ: {stats['disappeared_to_same']} å€‹")
        print(f"  ç›¸åŒé®ç½©ä¿ç•™: {stats['same_kept']} å€‹")
        print(f"  æ–°å¢é®ç½©ä¿ç•™: {stats['appeared_kept']} å€‹")
        print(f"  æ¶ˆå¤±é®ç½©ä¿ç•™: {stats['disappeared_kept']} å€‹")

        print(f"\nğŸ“ˆ é‡æ–°åˆ†é¡å¾Œæ•¸é‡:")
        print(f"  ç›¸åŒé®ç½©: {len(reclassified_same_masks)} å€‹")
        print(f"  æ¶ˆå¤±é®ç½©: {len(reclassified_disappeared_masks)} å€‹")
        print(f"  æ–°å¢é®ç½©: {len(reclassified_appeared_masks)} å€‹")

        return {
            'same_masks': reclassified_same_masks,
            'disappeared_masks': reclassified_disappeared_masks,
            'appeared_masks': reclassified_appeared_masks,
            'stats': stats
        }

def load_mask_images(mask_folder_path):
    """è¼‰å…¥æŒ‡å®šè³‡æ–™å¤¾å…§çš„æ‰€æœ‰é®ç½©å½±åƒ"""
    mask_folder = Path(mask_folder_path)
    mask_images = {}

    print(f"æ­£åœ¨è¼‰å…¥é®ç½©æª”æ¡ˆå¾: {mask_folder_path}")

    if not mask_folder.exists():
        print(f"âš ï¸ è­¦å‘Šï¼šé®ç½©è³‡æ–™å¤¾ä¸å­˜åœ¨: {mask_folder_path}")
        return mask_images

    for mask_file in mask_folder.glob("*.png"):
        mask_img = cv2.imread(str(mask_file), cv2.IMREAD_GRAYSCALE)
        if mask_img is not None:
            # äºŒå€¼åŒ–ï¼Œç¢ºä¿ç‚º0æˆ–255
            _, binary_mask = cv2.threshold(mask_img, 127, 255, cv2.THRESH_BINARY)
            mask_images[mask_file.name] = binary_mask
            print(f"  è¼‰å…¥é®ç½©: {mask_file.name}, å°ºå¯¸: {binary_mask.shape}")

    print(f"ç¸½å…±è¼‰å…¥ {len(mask_images)} å€‹é®ç½©æª”æ¡ˆ")
    return mask_images

def save_masks_to_folders(masks_dict, output_base_path, category_name):
    """å°‡é®ç½©å­—å…¸å„²å­˜åˆ°æŒ‡å®šè³‡æ–™å¤¾"""
    category_path = Path(output_base_path) / category_name
    category_path.mkdir(parents=True, exist_ok=True)

    print(f"ğŸ’¾ å„²å­˜ {len(masks_dict)} å€‹{category_name}é®ç½©åˆ°: {category_path}")

    for mask_name, mask in masks_dict.items():
        mask_file_path = category_path / mask_name
        cv2.imwrite(str(mask_file_path), mask)
        print(f"  âœ… å„²å­˜: {mask_name}")

    return str(category_path)

def create_mask_only_image(masks_dict, image_shape, color=(0, 255, 0)):
    """ğŸ†• å‰µå»ºåªåŒ…å«é®ç½©çš„åœ–åƒï¼ˆç´”é®ç½©ï¼ŒèƒŒæ™¯é€æ˜ï¼‰"""
    if not masks_dict:
        # å¦‚æœæ²’æœ‰é®ç½©ï¼Œè¿”å›å®Œå…¨é€æ˜çš„åœ–åƒ
        transparent_image = np.zeros((*image_shape[:2], 4), dtype=np.uint8)
        return transparent_image

    # ğŸ”§ é—œéµä¿®æ­£ï¼šå‰µå»º4é€šé“RGBAåœ–åƒï¼ˆæ”¯æ´é€æ˜åº¦ï¼‰
    mask_image = np.zeros((*image_shape[:2], 4), dtype=np.uint8)

    # å°‡æ‰€æœ‰é®ç½©åˆä½µ
    combined_mask = np.zeros(image_shape[:2], dtype=np.uint8)

    for mask_name, mask in masks_dict.items():
        if isinstance(mask, np.ndarray) and mask.size > 0:
            # ç¢ºä¿é®ç½©å°ºå¯¸èˆ‡åœ–åƒåŒ¹é…
            if mask.shape != image_shape[:2]:
                mask = cv2.resize(mask, (image_shape[1], image_shape[0]))

            # åˆä½µé®ç½©
            combined_mask = cv2.bitwise_or(combined_mask, mask)

    # å°‡åˆä½µçš„é®ç½©å€åŸŸè¨­ç‚ºæŒ‡å®šé¡è‰²ï¼ŒèƒŒæ™¯ä¿æŒé€æ˜
    mask_positions = combined_mask > 0
    if np.any(mask_positions):
        # ğŸ”§ é—œéµä¿®æ­£ï¼šåªæœ‰é®ç½©å€åŸŸæœ‰é¡è‰²ï¼Œå…¶ä»–å€åŸŸä¿æŒé€æ˜
        mask_image[mask_positions, 0] = color[0]  # B
        mask_image[mask_positions, 1] = color[1]  # G
        mask_image[mask_positions, 2] = color[2]  # R
        mask_image[mask_positions, 3] = 255       # Aï¼ˆä¸é€æ˜ï¼‰

    # èƒŒæ™¯å€åŸŸçš„ Alpha é€šé“å·²ç¶“æ˜¯ 0ï¼ˆé€æ˜ï¼‰

    print(f"ğŸ¨ å‰µå»ºé€æ˜èƒŒæ™¯é®ç½©åœ–åƒ: {len(masks_dict)} å€‹é®ç½©, é¡è‰²: {color}")

    return mask_image

def detect_changes_with_texture_analysis(image1_path, image2_path, matching_results_path,
                                       detection_output_path, params=None):
    """
    ğŸ†• ä¸»è¦åŠŸèƒ½ï¼šä½¿ç”¨ç´‹ç†åˆ†æé€²è¡Œè®ŠåŒ–æª¢æ¸¬ï¼ˆæ•´åˆè¦–è¦ºå·®ç•°é©—è­‰ï¼‰
    """

    try:
        print(f"\nğŸ” é–‹å§‹åŸ·è¡ŒåŸºæ–¼ç´‹ç†åˆ†æçš„è®ŠåŒ–æª¢æ¸¬ï¼ˆè¦–è¦ºå·®ç•°é©—è­‰ç‰ˆï¼‰...")
        print(f"ğŸ“ Matchingçµæœ: {matching_results_path}")
        print(f"ğŸ“ Detectionè¼¸å‡º: {detection_output_path}")

        # ğŸ”§ ä¿®æ­£ï¼šé…åˆç°¡åŒ–æª”åç­–ç•¥ï¼Œä½¿ç”¨ upload ç›®éŒ„ä¸­çš„æ¨™æº–æª”å
        detection_path = Path(detection_output_path)
        upload_dir = detection_path.parent / 'upload'

        print(f"ğŸ“‚ æœå°‹ä¸Šå‚³ç›®éŒ„: {upload_dir}")

        # ğŸ”§ é—œéµä¿®æ­£ï¼šç›´æ¥å°‹æ‰¾ç°¡åŒ–æª”åçš„åœ–ç‰‡
        image1_file = upload_dir / "image1.jpg"
        image2_file = upload_dir / "image2.jpg"

        if image1_file.exists() and image2_file.exists():
            # ä½¿ç”¨ç°¡åŒ–æª”å
            corrected_image1_path = str(image1_file)
            corrected_image2_path = str(image2_file)
            print(f"âœ… æ‰¾åˆ°ç°¡åŒ–æª”åçš„åœ–ç‰‡:")
            print(f"  åœ–ç‰‡1: {image1_file.name}")
            print(f"  åœ–ç‰‡2: {image2_file.name}")
        else:
            # ğŸ”§ å‚™ç”¨æ–¹æ¡ˆï¼šå¦‚æœæ²’æœ‰ç°¡åŒ–æª”åï¼ŒæŒ‰æª”åæ’åºå–å‰å…©å¼µ
            print(f"âš ï¸ æœªæ‰¾åˆ°ç°¡åŒ–æª”ååœ–ç‰‡ï¼Œä½¿ç”¨å‚™ç”¨æœå°‹...")

            all_images = []
            for ext in ['*.jpg', '*.jpeg', '*.png', '*.JPG', '*.JPEG', '*.PNG']:
                all_images.extend(list(upload_dir.glob(ext)))

            all_images.sort()
            if len(all_images) < 2:
                raise ValueError(f"Uploadç›®éŒ„ä¸­åªæ‰¾åˆ° {len(all_images)} å¼µåœ–ç‰‡ï¼Œéœ€è¦è‡³å°‘2å¼µ")

            corrected_image1_path = str(all_images[0])
            corrected_image2_path = str(all_images[1])

            print(f"ğŸ“‚ ä½¿ç”¨å‚™ç”¨åœ–ç‰‡:")
            print(f"  åœ–ç‰‡1: {Path(corrected_image1_path).name}")
            print(f"  åœ–ç‰‡2: {Path(corrected_image2_path).name}")

        print(f"\nğŸ”§ æœ€çµ‚ä½¿ç”¨çš„åœ–ç‰‡è·¯å¾‘:")
        print(f"  åœ–ç‰‡1: {corrected_image1_path}")
        print(f"  åœ–ç‰‡2: {corrected_image2_path}")

        # è¼‰å…¥åœ–ç‰‡
        img1 = cv2.imread(corrected_image1_path)
        img2 = cv2.imread(corrected_image2_path)

        if img1 is None or img2 is None:
            raise ValueError(f"ç„¡æ³•è¼‰å…¥åœ–ç‰‡: {corrected_image1_path} æˆ– {corrected_image2_path}")

        # æª¢æŸ¥åœ–ç‰‡æ˜¯å¦çœŸçš„ä¸åŒ
        if np.array_equal(img1, img2):
            print("âš ï¸ è­¦å‘Šï¼šè¼‰å…¥çš„å…©å¼µåœ–ç‰‡å®Œå…¨ç›¸åŒï¼")
        else:
            print("âœ… ç¢ºèªï¼šè¼‰å…¥çš„å…©å¼µåœ–ç‰‡ä¸åŒ")

        # ç¢ºä¿åœ–ç‰‡å¤§å°ä¸€è‡´
        if img1.shape != img2.shape:
            print(f"âš ï¸ èª¿æ•´åœ–ç‰‡2å°ºå¯¸: {img2.shape} -> {img1.shape}")
            img2 = cv2.resize(img2, (img1.shape[1], img1.shape[0]))

        # å»ºç«‹è¼¸å‡ºç›®éŒ„
        detection_path.mkdir(parents=True, exist_ok=True)

        # è¼‰å…¥ matching çµæœ
        matching_path = Path(matching_results_path)
        same_masks_path = matching_path / "Same"
        disappeared_masks_path = matching_path / "Disappear"
        appeared_masks_path = matching_path / "NewAdded"

        print(f"\nğŸ“‚ è¼‰å…¥ matching çµæœ...")
        original_same_masks = load_mask_images(same_masks_path)
        original_disappeared_masks = load_mask_images(disappeared_masks_path)
        original_appeared_masks = load_mask_images(appeared_masks_path)

        # åˆå§‹åŒ–ç´‹ç†åˆ†æå™¨å’Œé‡æ–°åˆ†é¡å™¨
        print(f"\nğŸ¤– åˆå§‹åŒ–ç´‹ç†åˆ†æç³»çµ±ï¼ˆè¦–è¦ºå·®ç•°é©—è­‰ç‰ˆï¼‰...")
        feature_extractor = ViTTextureExtractor()
        reclassifier = MaskReclassifier(feature_extractor)

        # åŸ·è¡Œé‡æ–°åˆ†é¡
        print(f"\nğŸ”„ åŸ·è¡Œç´‹ç†é‡æ–°åˆ†é¡...")
        reclassification_result = reclassifier.reclassify_masks(
            img1, img2,
            original_same_masks,
            original_disappeared_masks,
            original_appeared_masks
        )

        # å–å¾—é‡æ–°åˆ†é¡å¾Œçš„é®ç½©
        final_same_masks = reclassification_result['same_masks']
        final_disappeared_masks = reclassification_result['disappeared_masks']
        final_appeared_masks = reclassification_result['appeared_masks']

        # ğŸ’¾ Step 1: å„²å­˜é‡æ–°åˆ†é¡å¾Œçš„é®ç½©åˆ°è³‡æ–™å¤¾
        print(f"\nğŸ’¾ Step 1: å„²å­˜é‡æ–°åˆ†é¡é®ç½©åˆ° detection è³‡æ–™å¤¾...")

        same_folder_path = save_masks_to_folders(final_same_masks, detection_path, "Same")
        disappeared_folder_path = save_masks_to_folders(final_disappeared_masks, detection_path, "Disappear")
        appeared_folder_path = save_masks_to_folders(final_appeared_masks, detection_path, "NewAdded")

        # ğŸ–¼ï¸ Step 2: ç”Ÿæˆé€æ˜èƒŒæ™¯çµæœåœ–ç‰‡
        print(f"\nğŸ–¼ï¸ Step 2: ç”Ÿæˆé€æ˜èƒŒæ™¯çµæœåœ–ç‰‡...")

        # å®šç¾©é¡è‰² (BGRæ ¼å¼)
        same_color = (255, 150, 100)      # è—è‰² - ç›¸åŒé®ç½©
        disappeared_color = (0, 0, 255)   # ç¶ è‰² - æ¶ˆå¤±é®ç½©
        appeared_color = (0, 255, 0)      # ç´…è‰² - æ–°å¢é®ç½©

        # ç”Ÿæˆçµæœåœ–
        results = {}

        # å„²å­˜æ­£ç¢ºçš„åŸå§‹åœ–ç‰‡ï¼ˆJPGæ ¼å¼ï¼‰
        img1_original_path = detection_path / "image1_original.jpg"
        img2_original_path = detection_path / "image2_original.jpg"
        cv2.imwrite(str(img1_original_path), img1)
        cv2.imwrite(str(img2_original_path), img2)
        results['image1_original'] = str(img1_original_path)
        results['image2_original'] = str(img2_original_path)
        print(f"âœ… å„²å­˜æ­£ç¢ºçš„åŸå§‹åœ–ç‰‡:")
        print(f"  {img1_original_path.name} <- {Path(corrected_image1_path).name}")
        print(f"  {img2_original_path.name} <- {Path(corrected_image2_path).name}")

        # ğŸ”§ é—œéµä¿®æ­£ï¼šç”Ÿæˆé€æ˜èƒŒæ™¯çš„é®ç½©åœ–ç‰‡ï¼ˆPNGæ ¼å¼ï¼‰
        # image1_same_masks (é€æ˜èƒŒæ™¯)
        img1_same_masks = create_mask_only_image(final_same_masks, img1.shape, same_color)
        img1_same_path = detection_path / "image1_same_masks.png"  # æ”¹ç‚ºPNG
        cv2.imwrite(str(img1_same_path), img1_same_masks)
        results['image1_same_masks'] = str(img1_same_path)
        print(f"âœ… ç”Ÿæˆé€æ˜èƒŒæ™¯é®ç½©: {img1_same_path.name} ({len(final_same_masks)} å€‹ç›¸åŒé®ç½©)")

        # image2_same_masks (é€æ˜èƒŒæ™¯)
        img2_same_masks = create_mask_only_image(final_same_masks, img2.shape, same_color)
        img2_same_path = detection_path / "image2_same_masks.png"  # æ”¹ç‚ºPNG
        cv2.imwrite(str(img2_same_path), img2_same_masks)
        results['image2_same_masks'] = str(img2_same_path)
        print(f"âœ… ç”Ÿæˆé€æ˜èƒŒæ™¯é®ç½©: {img2_same_path.name} ({len(final_same_masks)} å€‹ç›¸åŒé®ç½©)")

        # image1_disappeared_masks (é€æ˜èƒŒæ™¯ - ç¶ è‰²)
        img1_disappeared_masks = create_mask_only_image(final_disappeared_masks, img1.shape, disappeared_color)
        img1_disappeared_path = detection_path / "image1_disappeared_masks.png"  # æ”¹ç‚ºPNG
        cv2.imwrite(str(img1_disappeared_path), img1_disappeared_masks)
        results['image1_disappeared_masks'] = str(img1_disappeared_path)
        print(f"âœ… ç”Ÿæˆé€æ˜èƒŒæ™¯é®ç½©: {img1_disappeared_path.name} ({len(final_disappeared_masks)} å€‹æ¶ˆå¤±é®ç½© - ç¶ è‰²)")

        # image2_appeared_masks (é€æ˜èƒŒæ™¯ - ç´…è‰²)
        img2_appeared_masks = create_mask_only_image(final_appeared_masks, img2.shape, appeared_color)
        img2_appeared_path = detection_path / "image2_appeared_masks.png"  # æ”¹ç‚ºPNG
        cv2.imwrite(str(img2_appeared_path), img2_appeared_masks)
        results['image2_appeared_masks'] = str(img2_appeared_path)
        print(f"âœ… ç”Ÿæˆé€æ˜èƒŒæ™¯é®ç½©: {img2_appeared_path.name} ({len(final_appeared_masks)} å€‹æ–°å¢é®ç½© - ç´…è‰²)")

        # ğŸ“Š Step 3: ç”Ÿæˆæª¢æ¸¬å ±å‘Š
        detection_stats = {
            'original_classification': {
                'same_masks': len(original_same_masks),
                'disappeared_masks': len(original_disappeared_masks),
                'appeared_masks': len(original_appeared_masks),
                'total': len(original_same_masks) + len(original_disappeared_masks) + len(original_appeared_masks)
            },
            'final_classification': {
                'same_masks': len(final_same_masks),
                'disappeared_masks': len(final_disappeared_masks),
                'appeared_masks': len(final_appeared_masks),
                'total': len(final_same_masks) + len(final_disappeared_masks) + len(final_appeared_masks)
            },
            'reclassification_stats': reclassification_result['stats']
        }

        # è¨ˆç®—æ”¹å–„æ•ˆæœ
        original_changes = len(original_disappeared_masks) + len(original_appeared_masks)
        final_changes = len(final_disappeared_masks) + len(final_appeared_masks)
        change_reduction = original_changes - final_changes
        improvement_percentage = (change_reduction / original_changes * 100) if original_changes > 0 else 0

        detection_stats['improvement'] = {
            'original_changes': original_changes,
            'final_changes': final_changes,
            'change_reduction': change_reduction,
            'improvement_percentage': improvement_percentage
        }

        print(f"\nğŸ“ˆ æª¢æ¸¬çµæœçµ±è¨ˆ:")
        print(f"  åŸå§‹è®ŠåŒ–æ•¸: {original_changes} å€‹")
        print(f"  æœ€çµ‚è®ŠåŒ–æ•¸: {final_changes} å€‹")
        print(f"  æ¸›å°‘èª¤åˆ¤: {change_reduction} å€‹ ({improvement_percentage:.1f}% æ”¹å–„)")

        # å„²å­˜æª¢æ¸¬å ±å‘Š
        report_path = detection_path / "detection_report.json"
        with open(report_path, 'w', encoding='utf-8') as f:
            json.dump(detection_stats, f, ensure_ascii=False, indent=2)

        print(f"\nâœ… ç´‹ç†æª¢æ¸¬å®Œæˆï¼ˆè¦–è¦ºå·®ç•°é©—è­‰ç‰ˆï¼‰ï¼")
        print(f"ğŸ“ è¼¸å‡ºè³‡æ–™å¤¾: {detection_path}")
        print(f"ğŸ“Š æª¢æ¸¬å ±å‘Š: {report_path}")

        return {
            'success': True,
            'output_path': str(detection_path),
            'generated_images': results,
            'mask_folders': {
                'same': same_folder_path,
                'disappeared': disappeared_folder_path,
                'appeared': appeared_folder_path
            },
            'statistics': detection_stats,
            'report_path': str(report_path)
        }

    except Exception as e:
        print(f"âŒ ç´‹ç†æª¢æ¸¬éç¨‹ç™¼ç”ŸéŒ¯èª¤: {str(e)}")
        import traceback
        traceback.print_exc()
        return {
            'success': False,
            'error': str(e),
            'output_path': detection_output_path,
            'generated_images': {},
            'mask_folders': {},
            'statistics': {},
            'report_path': ''
        }

if __name__ == "__main__":
    # æ¸¬è©¦ç”¨çš„ä¸»å‡½æ•¸
    print("ğŸ§ª æ¸¬è©¦ç´‹ç†æª¢æ¸¬æ¨¡çµ„ï¼ˆè¦–è¦ºå·®ç•°é©—è­‰ç‰ˆï¼‰...")

    # æ¸¬è©¦è·¯å¾‘ï¼ˆè«‹æ ¹æ“šå¯¦éš›æƒ…æ³ä¿®æ”¹ï¼‰
    image1_path = r"C:\Users\my544\Desktop\0808\results\runs\run_001\upload\image1.jpg"  # ğŸ”§ ä¿®æ­£ç‚ºç°¡åŒ–æª”å
    image2_path = r"C:\Users\my544\Desktop\0808\results\runs\run_001\upload\image2.jpg"  # ğŸ”§ ä¿®æ­£ç‚ºç°¡åŒ–æª”å
    matching_results_path = r"C:\Users\my544\Desktop\0808\results\runs\run_001\matching"
    detection_output_path = r"C:\Users\my544\Desktop\0808\results\runs\run_001\detection"

    # åŸ·è¡Œæª¢æ¸¬
    result = detect_changes_with_texture_analysis(
        image1_path, image2_path, matching_results_path, detection_output_path
    )

    if result['success']:
        print("ğŸ‰ æ¸¬è©¦æˆåŠŸï¼")
    else:
        print(f"âŒ æ¸¬è©¦å¤±æ•—: {result['error']}")
