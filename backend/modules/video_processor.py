"""
å½±ç‰‡è™•ç†æ¨¡çµ„
åŠŸèƒ½ï¼šå¾å½±ç‰‡æå–å½±æ ¼ï¼Œé€²è¡Œæ™‚é–“åºåˆ—è®ŠåŒ–æª¢æ¸¬
"""
import cv2
import numpy as np
from pathlib import Path
import tempfile
import shutil
import os
from typing import List, Tuple, Dict, Optional

class VideoProcessor:
    def __init__(self, output_dir: str):
        """
        åˆå§‹åŒ–å½±ç‰‡è™•ç†å™¨
        Args:
            output_dir: è¼¸å‡ºç›®éŒ„è·¯å¾‘
        """
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)

        # å‰µå»ºå­ç›®éŒ„
        self.frames_dir = self.output_dir / 'frames'
        self.frames_dir.mkdir(exist_ok=True)

    def extract_frames(self, video_path: str, interval_seconds: float = 1.0,
                      max_frames: int = 100) -> Dict:
        """
        å¾å½±ç‰‡æå–å½±æ ¼
        Args:
            video_path: å½±ç‰‡æª”æ¡ˆè·¯å¾‘
            interval_seconds: æå–é–“éš”ï¼ˆç§’ï¼‰
            max_frames: æœ€å¤§æå–å½±æ ¼æ•¸
        Returns:
            åŒ…å«æå–çµæœçš„å­—å…¸
        """
        try:
            # æ‰“é–‹å½±ç‰‡
            cap = cv2.VideoCapture(video_path)
            if not cap.isOpened():
                return {'success': False, 'error': 'ç„¡æ³•æ‰“é–‹å½±ç‰‡æª”æ¡ˆ'}

            # ç²å–å½±ç‰‡è³‡è¨Š
            fps = cap.get(cv2.CAP_PROP_FPS)
            frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            duration = frame_count / fps

            print(f"å½±ç‰‡è³‡è¨Š: FPS={fps}, ç¸½å½±æ ¼æ•¸={frame_count}, é•·åº¦={duration:.2f}ç§’")

            # è¨ˆç®—æå–é–“éš”ï¼ˆä»¥å½±æ ¼ç‚ºå–®ä½ï¼‰
            frame_interval = int(fps * interval_seconds)

            extracted_frames = []
            frame_number = 0
            extracted_count = 0

            # æ¸…ç©ºä¹‹å‰çš„å½±æ ¼
            if self.frames_dir.exists():
                shutil.rmtree(self.frames_dir)
            self.frames_dir.mkdir(exist_ok=True)

            while extracted_count < max_frames:
                # è¨­å®šåˆ°æŒ‡å®šå½±æ ¼ä½ç½®
                cap.set(cv2.CAP_PROP_POS_FRAMES, frame_number)

                ret, frame = cap.read()
                if not ret:
                    break

                # å„²å­˜å½±æ ¼
                timestamp = frame_number / fps
                filename = f"frame_{extracted_count:05d}_t{timestamp:.2f}s.jpg"
                frame_path = self.frames_dir / filename

                cv2.imwrite(str(frame_path), frame)

                extracted_frames.append({
                    'filename': filename,
                    'path': str(frame_path),
                    'frame_number': frame_number,
                    'timestamp': timestamp
                })

                print(f"æå–å½±æ ¼ {extracted_count + 1}: {filename} (æ™‚é–“: {timestamp:.2f}s)")

                extracted_count += 1
                frame_number += frame_interval

            cap.release()

            return {
                'success': True,
                'frames': extracted_frames,
                'video_info': {
                    'fps': fps,
                    'duration': duration,
                    'total_frames': frame_count,
                    'extracted_count': extracted_count
                },
                'output_dir': str(self.frames_dir)
            }

        except Exception as e:
            return {'success': False, 'error': f'æå–å½±æ ¼æ™‚ç™¼ç”ŸéŒ¯èª¤: {str(e)}'}

    def detect_temporal_changes(self, frames_data: List[Dict],
                               sensitivity: float = 0.1) -> Dict:
        """
        æª¢æ¸¬æ™‚é–“åºåˆ—è®ŠåŒ–
        Args:
            frames_data: å½±æ ¼è³‡æ–™åˆ—è¡¨
            sensitivity: æ•æ„Ÿåº¦é–¾å€¼
        Returns:
            è®ŠåŒ–æª¢æ¸¬çµæœ
        """
        try:
            changes = []

            for i in range(1, len(frames_data)):
                prev_frame_path = frames_data[i-1]['path']
                curr_frame_path = frames_data[i]['path']

                # è®€å–å½±æ ¼
                prev_img = cv2.imread(prev_frame_path)
                curr_img = cv2.imread(curr_frame_path)

                if prev_img is None or curr_img is None:
                    continue

                # è¨ˆç®—å·®ç•°
                change_score = self._calculate_frame_difference(prev_img, curr_img)

                if change_score > sensitivity:
                    changes.append({
                        'from_frame': i-1,
                        'to_frame': i,
                        'from_timestamp': frames_data[i-1]['timestamp'],
                        'to_timestamp': frames_data[i]['timestamp'],
                        'change_score': change_score,
                        'from_filename': frames_data[i-1]['filename'],
                        'to_filename': frames_data[i]['filename']
                    })

            return {
                'success': True,
                'changes': changes,
                'total_comparisons': len(frames_data) - 1,
                'significant_changes': len(changes)
            }

        except Exception as e:
            return {'success': False, 'error': f'æ™‚é–“åºåˆ—è®ŠåŒ–æª¢æ¸¬éŒ¯èª¤: {str(e)}'}

    def _calculate_frame_difference(self, img1: np.ndarray, img2: np.ndarray) -> float:
        """
        è¨ˆç®—å…©å€‹å½±æ ¼ä¹‹é–“çš„å·®ç•°åˆ†æ•¸
        Args:
            img1, img2: å¾…æ¯”è¼ƒçš„å½±æ ¼
        Returns:
            å·®ç•°åˆ†æ•¸ (0-1ä¹‹é–“)
        """
        # è½‰æ›ç‚ºç°éš
        gray1 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)
        gray2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)

        # è¨ˆç®—çµ•å°å·®ç•°
        diff = cv2.absdiff(gray1, gray2)

        # è¨ˆç®—å·®ç•°æ¯”ä¾‹
        total_pixels = diff.shape[0] * diff.shape[1]
        changed_pixels = np.count_nonzero(diff > 30)  # é–¾å€¼30

        change_ratio = changed_pixels / total_pixels

        return change_ratio

    def get_frame_pairs_for_analysis(self, frames_data: List[Dict],
                                   pair_strategy: str = 'consecutive') -> List[Tuple[str, str]]:
        """
        ç²å–ç”¨æ–¼åˆ†æçš„å½±æ ¼å°
        Args:
            frames_data: å½±æ ¼è³‡æ–™
            pair_strategy: é…å°ç­–ç•¥ ('consecutive', 'first_last', 'interval')
        Returns:
            å½±æ ¼å°è·¯å¾‘åˆ—è¡¨
        """
        pairs = []

        if pair_strategy == 'consecutive':
            # é€£çºŒå½±æ ¼é…å°
            for i in range(len(frames_data) - 1):
                pairs.append((frames_data[i]['path'], frames_data[i+1]['path']))

        elif pair_strategy == 'first_last':
            # ç¬¬ä¸€å€‹å’Œæœ€å¾Œä¸€å€‹å½±æ ¼
            if len(frames_data) >= 2:
                pairs.append((frames_data[0]['path'], frames_data[-1]['path']))

        elif pair_strategy == 'interval':
            # é–“éš”é…å°ï¼ˆæ¯nå€‹å½±æ ¼é…å°ä¸€æ¬¡ï¼‰
            interval = max(1, len(frames_data) // 10)  # æœ€å¤š10å°
            for i in range(0, len(frames_data) - interval, interval):
                pairs.append((frames_data[i]['path'], frames_data[i + interval]['path']))

        return pairs

    def cleanup(self):
        """æ¸…ç†è‡¨æ™‚æª”æ¡ˆ"""
        try:
            if self.frames_dir.exists():
                shutil.rmtree(self.frames_dir)
            print("å·²æ¸…ç†å½±ç‰‡è™•ç†è‡¨æ™‚æª”æ¡ˆ")
        except Exception as e:
            print(f"æ¸…ç†æª”æ¡ˆæ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")

def extract_video_frames_api(video_file_path: str, output_dir: str,
                           interval_seconds: float = 1.0, max_frames: int = 100) -> Dict:
    """
    APIä»‹é¢ï¼šå¾å½±ç‰‡æå–å½±æ ¼ - ç°¡åŒ–ç‰ˆæœ¬ï¼Œå°ˆæ³¨æ–¼å½±æ ¼æå–
    """
    processor = VideoProcessor(output_dir)
    result = processor.extract_frames(video_file_path, interval_seconds, max_frames)

    # ğŸ¯ ç°¡åŒ–ï¼šåªæå–å½±æ ¼ï¼Œä¸é€²è¡Œæ™‚é–“åºåˆ—åˆ†æ
    # æå–çš„å½±æ ¼å°‡ç”¨æ–¼å¾ŒçºŒçš„ç…§ç‰‡åˆ†ææµç¨‹

    return result
